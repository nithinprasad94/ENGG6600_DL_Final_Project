{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fd5d6c-f38a-4f0d-be11-bf63fbefb889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import mlflow\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b950702-2346-4d52-96f2-d572f4e7c063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10015 entries, 0 to 10014\n",
      "Columns: 785 entries, pixel0000 to label\n",
      "dtypes: int64(785)\n",
      "memory usage: 60.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### Data Exploration with the 28x28 image csv [FUNCTIONAL]\n",
    "\n",
    "print(\"Hello\")\n",
    "project_df = pd.read_csv('data/hmnist_28_28_L.csv')\n",
    "project_df.head(n=4)\n",
    "print(project_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf10dcc-dda9-4a15-9e06-d87c9dc584ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1135, 378, 379)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Do Train-Validation-Test Split on the Data (eg. 60/20/20)\n",
    "\n",
    "#read csv\n",
    "df = pd.read_csv('./data/skin_cancer_dataset.csv')\n",
    "\n",
    "#separate the features and labels\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "#split 60-40 for training dataset and a temp dataset that will be split to 50-50\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Second split of the temporary set: 50% for validation and 50% for test set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "#sanity check\n",
    "sizes = (len(X_train), len(X_val), len(X_test))\n",
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffed339d-a3f0-43b9-bbf8-f9a8d94b2299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1135, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Apply PCA (fit the PCA matrix using ONLY the training portion of the dataset). Transform each separately\n",
    "# fit pca on the training set only\n",
    "pca = PCA(n_components=0.80, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "\n",
    "#sanity check\n",
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f8817c-0e63-429e-bacf-0f035c85b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the PCA-transformed features and labels into PyTorch tensors\n",
    "train_features = torch.tensor(X_train_pca, dtype=torch.float)\n",
    "val_features = torch.tensor(X_val_pca, dtype=torch.float)\n",
    "test_features = torch.tensor(X_test_pca, dtype=torch.float)\n",
    "\n",
    "train_labels = torch.tensor(y_train.values, dtype=torch.long)  # Assuming y_train is a pandas Series\n",
    "val_labels = torch.tensor(y_val.values, dtype=torch.long)  # Assuming y_val is a pandas Series\n",
    "test_labels = torch.tensor(y_test.values, dtype=torch.long)  # Assuming y_test is a pandas Series\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_features, train_labels)\n",
    "val_dataset = TensorDataset(val_features, val_labels)\n",
    "test_dataset = TensorDataset(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0ac55c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_classes=7):\n",
    "        super(MLP, self).__init__()\n",
    "        # Define the network layers as before\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, size))\n",
    "            # layers.append(nn.LayerNorm(size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.5))\n",
    "            prev_size = size\n",
    "        layers.append(nn.Linear(prev_size, num_classes))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da286ef8-1e88-4050-b262-249719f8fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_validate_model(train_dataset, val_dataset, device, params):\n",
    "    # Model initialization\n",
    "    model = MLP(input_size=params['input_size'], hidden_sizes=params['hidden_sizes'], num_classes=7).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(params['epochs']):\n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds, val_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            output = model(data)\n",
    "            preds = torch.max(output, 1)[1]\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    val_accuracy = accuracy_score(val_targets, val_preds)\n",
    "    print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "    return val_accuracy, model\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    with torch.no_grad():  # Inference mode, no gradients needed\n",
    "        for data, labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            actuals.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb6fced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_grid = {\n",
    "    'lr': [0.001, 0.0005, 0.0001],\n",
    "    'hidden_sizes': [\n",
    "        [128, 64],\n",
    "        [128, 64, 32],\n",
    "        [128, 64, 32, 16],\n",
    "        [64,128,32]\n",
    "    ],\n",
    "    'batch_size': [16, 32, 64, 128]  # Example of adding batch size to the grid\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16df0fe9-ae7e-4368-af0d-09f94eec8cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with lr=0.001, hidden_sizes=[128, 64], batch_size=16\n",
      "Epoch 1, Loss: 8.058518409729004\n",
      "Epoch 2, Loss: 5.722539901733398\n",
      "Epoch 3, Loss: 5.417480945587158\n",
      "Epoch 4, Loss: 2.0664422512054443\n",
      "Epoch 5, Loss: 2.603742837905884\n",
      "Epoch 6, Loss: 1.9799559116363525\n",
      "Epoch 7, Loss: 2.3556976318359375\n",
      "Epoch 8, Loss: 2.5933165550231934\n",
      "Epoch 9, Loss: 1.760725498199463\n",
      "Epoch 10, Loss: 2.187429189682007\n",
      "Epoch 11, Loss: 1.9119384288787842\n",
      "Epoch 12, Loss: 1.4926857948303223\n",
      "Epoch 13, Loss: 1.9542561769485474\n",
      "Epoch 14, Loss: 1.6452908515930176\n",
      "Epoch 15, Loss: 1.7254005670547485\n",
      "Epoch 16, Loss: 2.078263521194458\n",
      "Epoch 17, Loss: 1.8188679218292236\n",
      "Epoch 18, Loss: 1.6525006294250488\n",
      "Epoch 19, Loss: 1.713840126991272\n",
      "Epoch 20, Loss: 1.8216408491134644\n",
      "Epoch 21, Loss: 1.7838021516799927\n",
      "Epoch 22, Loss: 1.5797027349472046\n",
      "Epoch 23, Loss: 1.809943675994873\n",
      "Epoch 24, Loss: 1.6712509393692017\n",
      "Epoch 25, Loss: 1.75022292137146\n",
      "Epoch 26, Loss: 1.7486965656280518\n",
      "Epoch 27, Loss: 1.7453519105911255\n",
      "Epoch 28, Loss: 1.9143832921981812\n",
      "Epoch 29, Loss: 2.1718761920928955\n",
      "Epoch 30, Loss: 1.8349003791809082\n",
      "Epoch 31, Loss: 2.1537652015686035\n",
      "Epoch 32, Loss: 1.8697758913040161\n",
      "Epoch 33, Loss: 1.8377114534378052\n",
      "Epoch 34, Loss: 3.0829336643218994\n",
      "Epoch 35, Loss: 1.6459795236587524\n",
      "Epoch 36, Loss: 1.9291249513626099\n",
      "Epoch 37, Loss: 1.638494849205017\n",
      "Epoch 38, Loss: 1.713386058807373\n",
      "Epoch 39, Loss: 1.788349986076355\n",
      "Epoch 40, Loss: 1.6917067766189575\n",
      "Epoch 41, Loss: 1.7766339778900146\n",
      "Epoch 42, Loss: 1.5336054563522339\n",
      "Epoch 43, Loss: 1.6727052927017212\n",
      "Epoch 44, Loss: 1.8581730127334595\n",
      "Epoch 45, Loss: 1.7196564674377441\n",
      "Epoch 46, Loss: 1.8544477224349976\n",
      "Epoch 47, Loss: 1.7813773155212402\n",
      "Epoch 48, Loss: 1.7591155767440796\n",
      "Epoch 49, Loss: 1.7635782957077026\n",
      "Epoch 50, Loss: 2.0210120677948\n",
      "Validation Accuracy: 0.2725\n",
      "Validation accuracy: 0.2724867724867725\n",
      "Training with lr=0.001, hidden_sizes=[128, 64], batch_size=32\n",
      "Epoch 1, Loss: 24.125263214111328\n",
      "Epoch 2, Loss: 10.094781875610352\n",
      "Epoch 3, Loss: 3.7834177017211914\n",
      "Epoch 4, Loss: 3.528795003890991\n",
      "Epoch 5, Loss: 2.0641326904296875\n",
      "Epoch 6, Loss: 2.1544723510742188\n",
      "Epoch 7, Loss: 3.8431053161621094\n",
      "Epoch 8, Loss: 2.004178762435913\n",
      "Epoch 9, Loss: 1.9121249914169312\n",
      "Epoch 10, Loss: 2.3277587890625\n",
      "Epoch 11, Loss: 2.004359006881714\n",
      "Epoch 12, Loss: 1.9036903381347656\n",
      "Epoch 13, Loss: 1.7938364744186401\n",
      "Epoch 14, Loss: 2.206775188446045\n",
      "Epoch 15, Loss: 1.7800102233886719\n",
      "Epoch 16, Loss: 1.9967411756515503\n",
      "Epoch 17, Loss: 1.7596261501312256\n",
      "Epoch 18, Loss: 2.256725549697876\n",
      "Epoch 19, Loss: 1.8505043983459473\n",
      "Epoch 20, Loss: 1.9360487461090088\n",
      "Epoch 21, Loss: 1.8758790493011475\n",
      "Epoch 22, Loss: 2.5279126167297363\n",
      "Epoch 23, Loss: 1.8186472654342651\n",
      "Epoch 24, Loss: 1.6841394901275635\n",
      "Epoch 25, Loss: 1.7195326089859009\n",
      "Epoch 26, Loss: 1.8228130340576172\n",
      "Epoch 27, Loss: 1.8553968667984009\n",
      "Epoch 28, Loss: 1.8866103887557983\n",
      "Epoch 29, Loss: 1.8054167032241821\n",
      "Epoch 30, Loss: 1.6684458255767822\n",
      "Epoch 31, Loss: 1.594091534614563\n",
      "Epoch 32, Loss: 1.8234659433364868\n",
      "Epoch 33, Loss: 2.0959670543670654\n",
      "Epoch 34, Loss: 1.940877079963684\n",
      "Epoch 35, Loss: 2.0435876846313477\n",
      "Epoch 36, Loss: 1.9562773704528809\n",
      "Epoch 37, Loss: 1.809152603149414\n",
      "Epoch 38, Loss: 1.576082468032837\n",
      "Epoch 39, Loss: 1.8218332529067993\n",
      "Epoch 40, Loss: 1.808267593383789\n",
      "Epoch 41, Loss: 1.6200398206710815\n",
      "Epoch 42, Loss: 1.61842679977417\n",
      "Epoch 43, Loss: 1.8603990077972412\n",
      "Epoch 44, Loss: 1.7125964164733887\n",
      "Epoch 45, Loss: 1.7712372541427612\n",
      "Epoch 46, Loss: 2.023057222366333\n",
      "Epoch 47, Loss: 1.9349339008331299\n",
      "Epoch 48, Loss: 1.802482008934021\n",
      "Epoch 49, Loss: 1.7032020092010498\n",
      "Epoch 50, Loss: 1.7166190147399902\n",
      "Validation Accuracy: 0.2778\n",
      "Validation accuracy: 0.2777777777777778\n",
      "Training with lr=0.001, hidden_sizes=[128, 64], batch_size=64\n",
      "Epoch 1, Loss: 28.538820266723633\n",
      "Epoch 2, Loss: 21.017946243286133\n",
      "Epoch 3, Loss: 6.830152988433838\n",
      "Epoch 4, Loss: 6.151534080505371\n",
      "Epoch 5, Loss: 3.441645860671997\n",
      "Epoch 6, Loss: 3.1238584518432617\n",
      "Epoch 7, Loss: 2.37241792678833\n",
      "Epoch 8, Loss: 2.4068551063537598\n",
      "Epoch 9, Loss: 1.8515814542770386\n",
      "Epoch 10, Loss: 2.213327169418335\n",
      "Epoch 11, Loss: 2.574631452560425\n",
      "Epoch 12, Loss: 2.2780935764312744\n",
      "Epoch 13, Loss: 2.1072683334350586\n",
      "Epoch 14, Loss: 2.68143630027771\n",
      "Epoch 15, Loss: 2.0116047859191895\n",
      "Epoch 16, Loss: 2.7437386512756348\n",
      "Epoch 17, Loss: 1.8210768699645996\n",
      "Epoch 18, Loss: 1.8365598917007446\n",
      "Epoch 19, Loss: 1.9140684604644775\n",
      "Epoch 20, Loss: 2.062750816345215\n",
      "Epoch 21, Loss: 1.8475239276885986\n",
      "Epoch 22, Loss: 2.131412982940674\n",
      "Epoch 23, Loss: 1.8084923028945923\n",
      "Epoch 24, Loss: 1.9125163555145264\n",
      "Epoch 25, Loss: 1.8999545574188232\n",
      "Epoch 26, Loss: 1.9000179767608643\n",
      "Epoch 27, Loss: 1.9362092018127441\n",
      "Epoch 28, Loss: 1.870691180229187\n",
      "Epoch 29, Loss: 1.762770652770996\n",
      "Epoch 30, Loss: 1.8708199262619019\n",
      "Epoch 31, Loss: 1.8617209196090698\n",
      "Epoch 32, Loss: 1.8541207313537598\n",
      "Epoch 33, Loss: 1.9089361429214478\n",
      "Epoch 34, Loss: 1.8837642669677734\n",
      "Epoch 35, Loss: 2.0157105922698975\n",
      "Epoch 36, Loss: 1.7782008647918701\n",
      "Epoch 37, Loss: 1.8212212324142456\n",
      "Epoch 38, Loss: 1.8641469478607178\n",
      "Epoch 39, Loss: 1.9271129369735718\n",
      "Epoch 40, Loss: 2.075406551361084\n",
      "Epoch 41, Loss: 1.8028303384780884\n",
      "Epoch 42, Loss: 1.838868498802185\n",
      "Epoch 43, Loss: 1.8014682531356812\n",
      "Epoch 44, Loss: 1.793845295906067\n",
      "Epoch 45, Loss: 1.8571991920471191\n",
      "Epoch 46, Loss: 1.7814830541610718\n",
      "Epoch 47, Loss: 1.7973355054855347\n",
      "Epoch 48, Loss: 1.7941209077835083\n",
      "Epoch 49, Loss: 1.720132827758789\n",
      "Epoch 50, Loss: 1.8105190992355347\n",
      "Validation Accuracy: 0.1852\n",
      "Validation accuracy: 0.18518518518518517\n",
      "Training with lr=0.001, hidden_sizes=[128, 64], batch_size=128\n",
      "Epoch 1, Loss: 45.59547424316406\n",
      "Epoch 2, Loss: 30.216405868530273\n",
      "Epoch 3, Loss: 15.7534818649292\n",
      "Epoch 4, Loss: 12.206013679504395\n",
      "Epoch 5, Loss: 8.00132942199707\n",
      "Epoch 6, Loss: 5.7969865798950195\n",
      "Epoch 7, Loss: 3.480644702911377\n",
      "Epoch 8, Loss: 3.2902309894561768\n",
      "Epoch 9, Loss: 3.5991203784942627\n",
      "Epoch 10, Loss: 2.8996737003326416\n",
      "Epoch 11, Loss: 2.1444942951202393\n",
      "Epoch 12, Loss: 2.447474241256714\n",
      "Epoch 13, Loss: 2.246272563934326\n",
      "Epoch 14, Loss: 2.4619510173797607\n",
      "Epoch 15, Loss: 2.1502737998962402\n",
      "Epoch 16, Loss: 2.033205270767212\n",
      "Epoch 17, Loss: 2.097810745239258\n",
      "Epoch 18, Loss: 2.0817630290985107\n",
      "Epoch 19, Loss: 1.984535574913025\n",
      "Epoch 20, Loss: 2.0631070137023926\n",
      "Epoch 21, Loss: 2.0093345642089844\n",
      "Epoch 22, Loss: 1.9539926052093506\n",
      "Epoch 23, Loss: 2.1046526432037354\n",
      "Epoch 24, Loss: 1.8934991359710693\n",
      "Epoch 25, Loss: 1.940483808517456\n",
      "Epoch 26, Loss: 1.9728976488113403\n",
      "Epoch 27, Loss: 1.882322072982788\n",
      "Epoch 28, Loss: 1.9466427564620972\n",
      "Epoch 29, Loss: 1.9463075399398804\n",
      "Epoch 30, Loss: 1.959403395652771\n",
      "Epoch 31, Loss: 1.8282002210617065\n",
      "Epoch 32, Loss: 2.0318126678466797\n",
      "Epoch 33, Loss: 1.899904727935791\n",
      "Epoch 34, Loss: 2.130887746810913\n",
      "Epoch 35, Loss: 2.1030664443969727\n",
      "Epoch 36, Loss: 2.029266834259033\n",
      "Epoch 37, Loss: 1.9031063318252563\n",
      "Epoch 38, Loss: 1.8685731887817383\n",
      "Epoch 39, Loss: 1.964705467224121\n",
      "Epoch 40, Loss: 2.1141486167907715\n",
      "Epoch 41, Loss: 1.9249416589736938\n",
      "Epoch 42, Loss: 1.9405839443206787\n",
      "Epoch 43, Loss: 2.2394495010375977\n",
      "Epoch 44, Loss: 1.8625346422195435\n",
      "Epoch 45, Loss: 1.9556502103805542\n",
      "Epoch 46, Loss: 1.8838984966278076\n",
      "Epoch 47, Loss: 1.896648645401001\n",
      "Epoch 48, Loss: 1.9152793884277344\n",
      "Epoch 49, Loss: 1.8849432468414307\n",
      "Epoch 50, Loss: 1.8564006090164185\n",
      "Validation Accuracy: 0.1720\n",
      "Validation accuracy: 0.17195767195767195\n",
      "Training with lr=0.001, hidden_sizes=[128, 64, 32], batch_size=16\n",
      "Epoch 1, Loss: 4.9339423179626465\n",
      "Epoch 2, Loss: 3.336487293243408\n",
      "Epoch 3, Loss: 2.025982618331909\n",
      "Epoch 4, Loss: 1.9164155721664429\n",
      "Epoch 5, Loss: 2.0017874240875244\n",
      "Epoch 6, Loss: 1.9794762134552002\n",
      "Epoch 7, Loss: 1.575411081314087\n",
      "Epoch 8, Loss: 1.9950145483016968\n",
      "Epoch 9, Loss: 1.931512713432312\n",
      "Epoch 10, Loss: 2.014709711074829\n",
      "Epoch 11, Loss: 1.9072836637496948\n",
      "Epoch 12, Loss: 1.9346405267715454\n",
      "Epoch 13, Loss: 1.8804012537002563\n",
      "Epoch 14, Loss: 1.9079614877700806\n",
      "Epoch 15, Loss: 1.9141050577163696\n",
      "Epoch 16, Loss: 1.9154280424118042\n",
      "Epoch 17, Loss: 2.0286810398101807\n",
      "Epoch 18, Loss: 1.985146164894104\n",
      "Epoch 19, Loss: 1.7274925708770752\n",
      "Epoch 20, Loss: 2.033437490463257\n",
      "Epoch 21, Loss: 1.6762313842773438\n",
      "Epoch 22, Loss: 2.0483622550964355\n",
      "Epoch 23, Loss: 1.7469521760940552\n",
      "Epoch 24, Loss: 1.6462332010269165\n",
      "Epoch 25, Loss: 1.7269439697265625\n",
      "Epoch 26, Loss: 1.911746859550476\n",
      "Epoch 27, Loss: 1.7758160829544067\n",
      "Epoch 28, Loss: 1.6747337579727173\n",
      "Epoch 29, Loss: 1.794911503791809\n",
      "Epoch 30, Loss: 2.051453113555908\n",
      "Epoch 31, Loss: 1.8539206981658936\n",
      "Epoch 32, Loss: 1.9929825067520142\n",
      "Epoch 33, Loss: 1.9417096376419067\n",
      "Epoch 34, Loss: 1.834652304649353\n",
      "Epoch 35, Loss: 1.8383277654647827\n",
      "Epoch 36, Loss: 1.9061806201934814\n",
      "Epoch 37, Loss: 1.7743525505065918\n",
      "Epoch 38, Loss: 1.7138326168060303\n",
      "Epoch 39, Loss: 1.7820764780044556\n",
      "Epoch 40, Loss: 1.611126184463501\n",
      "Epoch 41, Loss: 1.9326251745224\n",
      "Epoch 42, Loss: 1.9194310903549194\n",
      "Epoch 43, Loss: 2.05047345161438\n",
      "Epoch 44, Loss: 1.7233284711837769\n",
      "Epoch 45, Loss: 1.5112112760543823\n",
      "Epoch 46, Loss: 1.9980769157409668\n",
      "Epoch 47, Loss: 1.6593633890151978\n",
      "Epoch 48, Loss: 1.7946668863296509\n",
      "Epoch 49, Loss: 1.6575087308883667\n",
      "Epoch 50, Loss: 1.618336796760559\n",
      "Validation Accuracy: 0.2593\n",
      "Validation accuracy: 0.25925925925925924\n",
      "Training with lr=0.001, hidden_sizes=[128, 64, 32], batch_size=32\n",
      "Epoch 1, Loss: 8.064480781555176\n",
      "Epoch 2, Loss: 4.561561107635498\n",
      "Epoch 3, Loss: 4.755332946777344\n",
      "Epoch 4, Loss: 1.9631390571594238\n",
      "Epoch 5, Loss: 2.1904633045196533\n",
      "Epoch 6, Loss: 2.4620120525360107\n",
      "Epoch 7, Loss: 1.8947312831878662\n",
      "Epoch 8, Loss: 1.759064793586731\n",
      "Epoch 9, Loss: 2.0015716552734375\n",
      "Epoch 10, Loss: 2.114736557006836\n",
      "Epoch 11, Loss: 1.9640766382217407\n",
      "Epoch 12, Loss: 1.8653175830841064\n",
      "Epoch 13, Loss: 1.675275206565857\n",
      "Epoch 14, Loss: 2.2068185806274414\n",
      "Epoch 15, Loss: 1.740936517715454\n",
      "Epoch 16, Loss: 1.7896379232406616\n",
      "Epoch 17, Loss: 1.841637134552002\n",
      "Epoch 18, Loss: 1.9891363382339478\n",
      "Epoch 19, Loss: 2.0847697257995605\n",
      "Epoch 20, Loss: 1.8711276054382324\n",
      "Epoch 21, Loss: 1.869346022605896\n",
      "Epoch 22, Loss: 1.9406858682632446\n",
      "Epoch 23, Loss: 1.8864675760269165\n",
      "Epoch 24, Loss: 1.986826777458191\n",
      "Epoch 25, Loss: 1.8527979850769043\n",
      "Epoch 26, Loss: 1.9098950624465942\n",
      "Epoch 27, Loss: 1.9605449438095093\n",
      "Epoch 28, Loss: 2.1449332237243652\n",
      "Epoch 29, Loss: 1.9579187631607056\n",
      "Epoch 30, Loss: 1.816643476486206\n",
      "Epoch 31, Loss: 1.833309531211853\n",
      "Epoch 32, Loss: 1.991084337234497\n",
      "Epoch 33, Loss: 1.8317444324493408\n",
      "Epoch 34, Loss: 1.904610276222229\n",
      "Epoch 35, Loss: 1.9447296857833862\n",
      "Epoch 36, Loss: 1.8852882385253906\n",
      "Epoch 37, Loss: 1.7969697713851929\n",
      "Epoch 38, Loss: 1.7862086296081543\n",
      "Epoch 39, Loss: 1.6479299068450928\n",
      "Epoch 40, Loss: 2.04015851020813\n",
      "Epoch 41, Loss: 1.9213248491287231\n",
      "Epoch 42, Loss: 1.7544662952423096\n",
      "Epoch 43, Loss: 1.761324405670166\n",
      "Epoch 44, Loss: 1.8437824249267578\n",
      "Epoch 45, Loss: 1.7395365238189697\n",
      "Epoch 46, Loss: 1.982850193977356\n",
      "Epoch 47, Loss: 1.7944496870040894\n",
      "Epoch 48, Loss: 1.711292028427124\n",
      "Epoch 49, Loss: 1.9092376232147217\n",
      "Epoch 50, Loss: 1.8239212036132812\n",
      "Validation Accuracy: 0.2963\n",
      "Validation accuracy: 0.2962962962962963\n",
      "Training with lr=0.001, hidden_sizes=[128, 64, 32], batch_size=64\n",
      "Epoch 1, Loss: 13.905111312866211\n",
      "Epoch 2, Loss: 7.350677013397217\n",
      "Epoch 3, Loss: 4.2560954093933105\n",
      "Epoch 4, Loss: 3.914367914199829\n",
      "Epoch 5, Loss: 2.9138903617858887\n",
      "Epoch 6, Loss: 2.8084535598754883\n",
      "Epoch 7, Loss: 2.0909838676452637\n",
      "Epoch 8, Loss: 1.8728337287902832\n",
      "Epoch 9, Loss: 2.348330020904541\n",
      "Epoch 10, Loss: 2.0427708625793457\n",
      "Epoch 11, Loss: 2.125995635986328\n",
      "Epoch 12, Loss: 2.1226086616516113\n",
      "Epoch 13, Loss: 2.1253340244293213\n",
      "Epoch 14, Loss: 1.990877389907837\n",
      "Epoch 15, Loss: 1.8725966215133667\n",
      "Epoch 16, Loss: 1.8069093227386475\n",
      "Epoch 17, Loss: 1.9417177438735962\n",
      "Epoch 18, Loss: 2.011026382446289\n",
      "Epoch 19, Loss: 2.013944149017334\n",
      "Epoch 20, Loss: 1.8538907766342163\n",
      "Epoch 21, Loss: 1.8597475290298462\n",
      "Epoch 22, Loss: 2.3944544792175293\n",
      "Epoch 23, Loss: 1.9712927341461182\n",
      "Epoch 24, Loss: 1.9421672821044922\n",
      "Epoch 25, Loss: 1.9270908832550049\n",
      "Epoch 26, Loss: 1.9844907522201538\n",
      "Epoch 27, Loss: 2.2672152519226074\n",
      "Epoch 28, Loss: 1.8571202754974365\n",
      "Epoch 29, Loss: 1.9276505708694458\n",
      "Epoch 30, Loss: 1.877304196357727\n",
      "Epoch 31, Loss: 1.8979159593582153\n",
      "Epoch 32, Loss: 1.8670134544372559\n",
      "Epoch 33, Loss: 1.8772265911102295\n",
      "Epoch 34, Loss: 1.9198015928268433\n",
      "Epoch 35, Loss: 1.8407306671142578\n",
      "Epoch 36, Loss: 1.9336495399475098\n",
      "Epoch 37, Loss: 1.894514799118042\n",
      "Epoch 38, Loss: 1.8724384307861328\n",
      "Epoch 39, Loss: 1.8179290294647217\n",
      "Epoch 40, Loss: 1.8484281301498413\n",
      "Epoch 41, Loss: 1.87449049949646\n",
      "Epoch 42, Loss: 1.9223246574401855\n",
      "Epoch 43, Loss: 1.8057057857513428\n",
      "Epoch 44, Loss: 1.8175915479660034\n",
      "Epoch 45, Loss: 1.8423457145690918\n",
      "Epoch 46, Loss: 1.9399359226226807\n",
      "Epoch 47, Loss: 2.1490180492401123\n",
      "Epoch 48, Loss: 1.826188087463379\n",
      "Epoch 49, Loss: 1.8607842922210693\n",
      "Epoch 50, Loss: 1.9046924114227295\n",
      "Validation Accuracy: 0.2249\n",
      "Validation accuracy: 0.22486772486772486\n",
      "Training with lr=0.001, hidden_sizes=[128, 64, 32], batch_size=128\n",
      "Epoch 1, Loss: 16.663820266723633\n",
      "Epoch 2, Loss: 13.22299861907959\n",
      "Epoch 3, Loss: 7.726174354553223\n",
      "Epoch 4, Loss: 6.260470867156982\n",
      "Epoch 5, Loss: 4.77517557144165\n",
      "Epoch 6, Loss: 3.6287009716033936\n",
      "Epoch 7, Loss: 3.4169762134552\n",
      "Epoch 8, Loss: 2.647338390350342\n",
      "Epoch 9, Loss: 2.7241313457489014\n",
      "Epoch 10, Loss: 3.104158401489258\n",
      "Epoch 11, Loss: 2.3867082595825195\n",
      "Epoch 12, Loss: 2.648589849472046\n",
      "Epoch 13, Loss: 2.2520389556884766\n",
      "Epoch 14, Loss: 2.300703525543213\n",
      "Epoch 15, Loss: 2.027893304824829\n",
      "Epoch 16, Loss: 2.325958490371704\n",
      "Epoch 17, Loss: 2.0627551078796387\n",
      "Epoch 18, Loss: 1.9495280981063843\n",
      "Epoch 19, Loss: 2.050924301147461\n",
      "Epoch 20, Loss: 1.9613542556762695\n",
      "Epoch 21, Loss: 2.0198159217834473\n",
      "Epoch 22, Loss: 1.9164937734603882\n",
      "Epoch 23, Loss: 1.998370885848999\n",
      "Epoch 24, Loss: 1.967220425605774\n",
      "Epoch 25, Loss: 1.9058582782745361\n",
      "Epoch 26, Loss: 2.0533788204193115\n",
      "Epoch 27, Loss: 1.9782259464263916\n",
      "Epoch 28, Loss: 1.9092836380004883\n",
      "Epoch 29, Loss: 1.8721591234207153\n",
      "Epoch 30, Loss: 1.9362810850143433\n",
      "Epoch 31, Loss: 1.9316487312316895\n",
      "Epoch 32, Loss: 1.9437087774276733\n",
      "Epoch 33, Loss: 1.9005600214004517\n",
      "Epoch 34, Loss: 1.9358127117156982\n",
      "Epoch 35, Loss: 1.89945650100708\n",
      "Epoch 36, Loss: 2.0031862258911133\n",
      "Epoch 37, Loss: 1.875427007675171\n",
      "Epoch 38, Loss: 1.9062554836273193\n",
      "Epoch 39, Loss: 1.952553629875183\n",
      "Epoch 40, Loss: 1.9333765506744385\n",
      "Epoch 41, Loss: 1.9291795492172241\n",
      "Epoch 42, Loss: 1.9191274642944336\n",
      "Epoch 43, Loss: 1.9078028202056885\n",
      "Epoch 44, Loss: 1.9117099046707153\n",
      "Epoch 45, Loss: 1.888283371925354\n",
      "Epoch 46, Loss: 2.1361095905303955\n",
      "Epoch 47, Loss: 1.8674746751785278\n",
      "Epoch 48, Loss: 1.88916015625\n",
      "Epoch 49, Loss: 1.909637451171875\n",
      "Epoch 50, Loss: 1.897330641746521\n",
      "Validation Accuracy: 0.1587\n",
      "Validation accuracy: 0.15873015873015872\n",
      "Training with lr=0.001, hidden_sizes=[128, 64, 32, 16], batch_size=16\n",
      "Epoch 1, Loss: 2.518131732940674\n",
      "Epoch 2, Loss: 2.2566792964935303\n",
      "Epoch 3, Loss: 1.938522219657898\n",
      "Epoch 4, Loss: 2.5609099864959717\n",
      "Epoch 5, Loss: 2.14678955078125\n",
      "Epoch 6, Loss: 1.903875470161438\n",
      "Epoch 7, Loss: 1.8927356004714966\n",
      "Epoch 8, Loss: 1.8136084079742432\n",
      "Epoch 9, Loss: 1.8319804668426514\n",
      "Epoch 10, Loss: 1.8975399732589722\n",
      "Epoch 11, Loss: 1.7696701288223267\n",
      "Epoch 12, Loss: 1.9999029636383057\n",
      "Epoch 13, Loss: 1.8697197437286377\n",
      "Epoch 14, Loss: 2.0337324142456055\n",
      "Epoch 15, Loss: 1.9704663753509521\n",
      "Epoch 16, Loss: 1.9064507484436035\n",
      "Epoch 17, Loss: 2.07692813873291\n",
      "Epoch 18, Loss: 1.7998324632644653\n",
      "Epoch 19, Loss: 1.711714506149292\n",
      "Epoch 20, Loss: 1.910030722618103\n",
      "Epoch 21, Loss: 1.8163964748382568\n",
      "Epoch 22, Loss: 1.7225382328033447\n",
      "Epoch 23, Loss: 1.9355065822601318\n",
      "Epoch 24, Loss: 1.864467740058899\n",
      "Epoch 25, Loss: 1.8416874408721924\n",
      "Epoch 26, Loss: 1.9463086128234863\n",
      "Epoch 27, Loss: 1.675981879234314\n",
      "Epoch 28, Loss: 1.7377574443817139\n",
      "Epoch 29, Loss: 1.680841326713562\n",
      "Epoch 30, Loss: 1.5776710510253906\n",
      "Epoch 31, Loss: 1.7223628759384155\n",
      "Epoch 32, Loss: 1.9060206413269043\n",
      "Epoch 33, Loss: 2.3155248165130615\n",
      "Epoch 34, Loss: 1.8588252067565918\n",
      "Epoch 35, Loss: 1.8273111581802368\n",
      "Epoch 36, Loss: 1.8209855556488037\n",
      "Epoch 37, Loss: 1.928529143333435\n",
      "Epoch 38, Loss: 2.121272087097168\n",
      "Epoch 39, Loss: 1.7785664796829224\n",
      "Epoch 40, Loss: 1.8560577630996704\n",
      "Epoch 41, Loss: 1.834835171699524\n",
      "Epoch 42, Loss: 1.644859790802002\n",
      "Epoch 43, Loss: 1.9013726711273193\n",
      "Epoch 44, Loss: 1.647739052772522\n",
      "Epoch 45, Loss: 1.6663708686828613\n",
      "Epoch 46, Loss: 1.558337688446045\n",
      "Epoch 47, Loss: 1.9355430603027344\n",
      "Epoch 48, Loss: 1.5866197347640991\n",
      "Epoch 49, Loss: 1.7821860313415527\n",
      "Epoch 50, Loss: 1.5575101375579834\n",
      "Validation Accuracy: 0.2963\n",
      "Validation accuracy: 0.2962962962962963\n",
      "Training with lr=0.001, hidden_sizes=[128, 64, 32, 16], batch_size=32\n",
      "Epoch 1, Loss: 4.226635456085205\n",
      "Epoch 2, Loss: 3.6838808059692383\n",
      "Epoch 3, Loss: 2.932055711746216\n",
      "Epoch 4, Loss: 2.809677839279175\n",
      "Epoch 5, Loss: 2.137596368789673\n",
      "Epoch 6, Loss: 2.5752949714660645\n",
      "Epoch 7, Loss: 2.680335521697998\n",
      "Epoch 8, Loss: 1.9408758878707886\n",
      "Epoch 9, Loss: 2.1284024715423584\n",
      "Epoch 10, Loss: 2.0251870155334473\n",
      "Epoch 11, Loss: 1.9897887706756592\n",
      "Epoch 12, Loss: 2.0342705249786377\n",
      "Epoch 13, Loss: 1.8221839666366577\n",
      "Epoch 14, Loss: 2.027883529663086\n",
      "Epoch 15, Loss: 1.97202467918396\n",
      "Epoch 16, Loss: 2.157444715499878\n",
      "Epoch 17, Loss: 1.9017845392227173\n",
      "Epoch 18, Loss: 1.9153879880905151\n",
      "Epoch 19, Loss: 1.9008828401565552\n",
      "Epoch 20, Loss: 1.8890655040740967\n",
      "Epoch 21, Loss: 1.874043345451355\n",
      "Epoch 22, Loss: 1.9354465007781982\n",
      "Epoch 23, Loss: 1.833970308303833\n",
      "Epoch 24, Loss: 1.7923954725265503\n",
      "Epoch 25, Loss: 1.8775337934494019\n",
      "Epoch 26, Loss: 1.9184457063674927\n",
      "Epoch 27, Loss: 1.9183921813964844\n",
      "Epoch 28, Loss: 1.857330322265625\n",
      "Epoch 29, Loss: 1.701658010482788\n",
      "Epoch 30, Loss: 1.910163164138794\n",
      "Epoch 31, Loss: 1.8540757894515991\n",
      "Epoch 32, Loss: 1.9751136302947998\n",
      "Epoch 33, Loss: 1.7103513479232788\n",
      "Epoch 34, Loss: 1.875366449356079\n",
      "Epoch 35, Loss: 1.9070791006088257\n",
      "Epoch 36, Loss: 1.916735053062439\n",
      "Epoch 37, Loss: 1.776085376739502\n",
      "Epoch 38, Loss: 1.9392939805984497\n",
      "Epoch 39, Loss: 1.7343004941940308\n",
      "Epoch 40, Loss: 1.7345468997955322\n",
      "Epoch 41, Loss: 1.8150291442871094\n",
      "Epoch 42, Loss: 1.9322693347930908\n",
      "Epoch 43, Loss: 1.8330708742141724\n",
      "Epoch 44, Loss: 1.7167980670928955\n",
      "Epoch 45, Loss: 1.9588459730148315\n",
      "Epoch 46, Loss: 1.913638949394226\n",
      "Epoch 47, Loss: 1.9799033403396606\n",
      "Epoch 48, Loss: 1.691153645515442\n",
      "Epoch 49, Loss: 1.8276536464691162\n",
      "Epoch 50, Loss: 1.9193828105926514\n",
      "Validation Accuracy: 0.2963\n",
      "Validation accuracy: 0.2962962962962963\n",
      "Training with lr=0.001, hidden_sizes=[128, 64, 32, 16], batch_size=64\n",
      "Epoch 1, Loss: 7.3095197677612305\n",
      "Epoch 2, Loss: 3.867551326751709\n",
      "Epoch 3, Loss: 2.776937246322632\n",
      "Epoch 4, Loss: 2.8473727703094482\n",
      "Epoch 5, Loss: 2.381676435470581\n",
      "Epoch 6, Loss: 2.2628700733184814\n",
      "Epoch 7, Loss: 2.322669506072998\n",
      "Epoch 8, Loss: 2.0278682708740234\n",
      "Epoch 9, Loss: 2.301992177963257\n",
      "Epoch 10, Loss: 1.9284371137619019\n",
      "Epoch 11, Loss: 2.409689426422119\n",
      "Epoch 12, Loss: 1.9164271354675293\n",
      "Epoch 13, Loss: 2.125046968460083\n",
      "Epoch 14, Loss: 2.2524259090423584\n",
      "Epoch 15, Loss: 1.9333140850067139\n",
      "Epoch 16, Loss: 1.945101261138916\n",
      "Epoch 17, Loss: 1.9662094116210938\n",
      "Epoch 18, Loss: 1.8776394128799438\n",
      "Epoch 19, Loss: 1.8825161457061768\n",
      "Epoch 20, Loss: 2.0948593616485596\n",
      "Epoch 21, Loss: 1.9849238395690918\n",
      "Epoch 22, Loss: 1.8822444677352905\n",
      "Epoch 23, Loss: 2.0115745067596436\n",
      "Epoch 24, Loss: 1.8754462003707886\n",
      "Epoch 25, Loss: 1.883992075920105\n",
      "Epoch 26, Loss: 1.934165596961975\n",
      "Epoch 27, Loss: 1.9183166027069092\n",
      "Epoch 28, Loss: 1.8753639459609985\n",
      "Epoch 29, Loss: 1.9752134084701538\n",
      "Epoch 30, Loss: 1.8856583833694458\n",
      "Epoch 31, Loss: 1.8899909257888794\n",
      "Epoch 32, Loss: 1.9319264888763428\n",
      "Epoch 33, Loss: 1.931546926498413\n",
      "Epoch 34, Loss: 1.8570923805236816\n",
      "Epoch 35, Loss: 1.9210623502731323\n",
      "Epoch 36, Loss: 1.9428303241729736\n",
      "Epoch 37, Loss: 1.874144196510315\n",
      "Epoch 38, Loss: 1.8767412900924683\n",
      "Epoch 39, Loss: 1.8681076765060425\n",
      "Epoch 40, Loss: 1.894322156906128\n",
      "Epoch 41, Loss: 1.869728684425354\n",
      "Epoch 42, Loss: 1.904426097869873\n",
      "Epoch 43, Loss: 1.8680624961853027\n",
      "Epoch 44, Loss: 1.8695240020751953\n",
      "Epoch 45, Loss: 1.9070727825164795\n",
      "Epoch 46, Loss: 1.913189172744751\n",
      "Epoch 47, Loss: 1.8893239498138428\n",
      "Epoch 48, Loss: 1.9014569520950317\n",
      "Epoch 49, Loss: 1.813105821609497\n",
      "Epoch 50, Loss: 1.825194001197815\n",
      "Validation Accuracy: 0.1587\n",
      "Validation accuracy: 0.15873015873015872\n",
      "Training with lr=0.001, hidden_sizes=[128, 64, 32, 16], batch_size=128\n",
      "Epoch 1, Loss: 9.434097290039062\n",
      "Epoch 2, Loss: 4.730074882507324\n",
      "Epoch 3, Loss: 3.81569766998291\n",
      "Epoch 4, Loss: 2.943861246109009\n",
      "Epoch 5, Loss: 2.990814685821533\n",
      "Epoch 6, Loss: 2.5937716960906982\n",
      "Epoch 7, Loss: 2.5687496662139893\n",
      "Epoch 8, Loss: 2.4386842250823975\n",
      "Epoch 9, Loss: 2.327284574508667\n",
      "Epoch 10, Loss: 2.2206711769104004\n",
      "Epoch 11, Loss: 2.071295738220215\n",
      "Epoch 12, Loss: 2.0948753356933594\n",
      "Epoch 13, Loss: 2.009270191192627\n",
      "Epoch 14, Loss: 2.0924501419067383\n",
      "Epoch 15, Loss: 2.104111433029175\n",
      "Epoch 16, Loss: 1.9968658685684204\n",
      "Epoch 17, Loss: 2.0973753929138184\n",
      "Epoch 18, Loss: 2.119126319885254\n",
      "Epoch 19, Loss: 1.957216501235962\n",
      "Epoch 20, Loss: 2.0269200801849365\n",
      "Epoch 21, Loss: 1.9748964309692383\n",
      "Epoch 22, Loss: 1.9706904888153076\n",
      "Epoch 23, Loss: 1.973043441772461\n",
      "Epoch 24, Loss: 1.9684669971466064\n",
      "Epoch 25, Loss: 2.039191484451294\n",
      "Epoch 26, Loss: 1.9257910251617432\n",
      "Epoch 27, Loss: 1.9964473247528076\n",
      "Epoch 28, Loss: 1.9511421918869019\n",
      "Epoch 29, Loss: 1.8974591493606567\n",
      "Epoch 30, Loss: 1.8966739177703857\n",
      "Epoch 31, Loss: 2.0105485916137695\n",
      "Epoch 32, Loss: 1.9420561790466309\n",
      "Epoch 33, Loss: 1.9197691679000854\n",
      "Epoch 34, Loss: 1.9236853122711182\n",
      "Epoch 35, Loss: 1.8850598335266113\n",
      "Epoch 36, Loss: 1.974188208580017\n",
      "Epoch 37, Loss: 1.9564470052719116\n",
      "Epoch 38, Loss: 2.007718086242676\n",
      "Epoch 39, Loss: 1.9031256437301636\n",
      "Epoch 40, Loss: 1.8822039365768433\n",
      "Epoch 41, Loss: 1.8839443922042847\n",
      "Epoch 42, Loss: 1.9454072713851929\n",
      "Epoch 43, Loss: 1.9018594026565552\n",
      "Epoch 44, Loss: 1.8815351724624634\n",
      "Epoch 45, Loss: 1.8324739933013916\n",
      "Epoch 46, Loss: 1.9042950868606567\n",
      "Epoch 47, Loss: 1.8767164945602417\n",
      "Epoch 48, Loss: 1.9518234729766846\n",
      "Epoch 49, Loss: 1.9296281337738037\n",
      "Epoch 50, Loss: 1.9350688457489014\n",
      "Validation Accuracy: 0.1878\n",
      "Validation accuracy: 0.18783068783068782\n",
      "Training with lr=0.001, hidden_sizes=[64, 128, 32], batch_size=16\n",
      "Epoch 1, Loss: 6.053881645202637\n",
      "Epoch 2, Loss: 3.218926191329956\n",
      "Epoch 3, Loss: 2.019726276397705\n",
      "Epoch 4, Loss: 2.0059714317321777\n",
      "Epoch 5, Loss: 1.8692034482955933\n",
      "Epoch 6, Loss: 1.8693009614944458\n",
      "Epoch 7, Loss: 1.9877508878707886\n",
      "Epoch 8, Loss: 2.026123523712158\n",
      "Epoch 9, Loss: 1.9085532426834106\n",
      "Epoch 10, Loss: 1.896098256111145\n",
      "Epoch 11, Loss: 1.8117733001708984\n",
      "Epoch 12, Loss: 1.8232485055923462\n",
      "Epoch 13, Loss: 1.8875172138214111\n",
      "Epoch 14, Loss: 1.8697190284729004\n",
      "Epoch 15, Loss: 1.87820565700531\n",
      "Epoch 16, Loss: 1.952735424041748\n",
      "Epoch 17, Loss: 1.9311649799346924\n",
      "Epoch 18, Loss: 1.8420113325119019\n",
      "Epoch 19, Loss: 1.8365858793258667\n",
      "Epoch 20, Loss: 1.8679622411727905\n",
      "Epoch 21, Loss: 1.9190598726272583\n",
      "Epoch 22, Loss: 1.8294715881347656\n",
      "Epoch 23, Loss: 1.7773977518081665\n",
      "Epoch 24, Loss: 1.8275179862976074\n",
      "Epoch 25, Loss: 1.861523151397705\n",
      "Epoch 26, Loss: 1.818948745727539\n",
      "Epoch 27, Loss: 1.768519639968872\n",
      "Epoch 28, Loss: 1.968227505683899\n",
      "Epoch 29, Loss: 2.0077240467071533\n",
      "Epoch 30, Loss: 1.7828052043914795\n",
      "Epoch 31, Loss: 1.993545413017273\n",
      "Epoch 32, Loss: 1.8723456859588623\n",
      "Epoch 33, Loss: 1.8647539615631104\n",
      "Epoch 34, Loss: 1.8621046543121338\n",
      "Epoch 35, Loss: 1.8225752115249634\n",
      "Epoch 36, Loss: 1.866252064704895\n",
      "Epoch 37, Loss: 1.8587803840637207\n",
      "Epoch 38, Loss: 1.8806209564208984\n",
      "Epoch 39, Loss: 1.8623378276824951\n",
      "Epoch 40, Loss: 1.7560869455337524\n",
      "Epoch 41, Loss: 1.987562656402588\n",
      "Epoch 42, Loss: 1.8158713579177856\n",
      "Epoch 43, Loss: 1.914122462272644\n",
      "Epoch 44, Loss: 1.859639048576355\n",
      "Epoch 45, Loss: 1.8849366903305054\n",
      "Epoch 46, Loss: 1.9546854496002197\n",
      "Epoch 47, Loss: 1.8746315240859985\n",
      "Epoch 48, Loss: 1.9788559675216675\n",
      "Epoch 49, Loss: 1.8636382818222046\n",
      "Epoch 50, Loss: 1.8570421934127808\n",
      "Validation Accuracy: 0.1720\n",
      "Validation accuracy: 0.17195767195767195\n",
      "Training with lr=0.001, hidden_sizes=[64, 128, 32], batch_size=32\n",
      "Epoch 1, Loss: 8.617228507995605\n",
      "Epoch 2, Loss: 3.335545778274536\n",
      "Epoch 3, Loss: 2.122218370437622\n",
      "Epoch 4, Loss: 1.7696818113327026\n",
      "Epoch 5, Loss: 1.9583505392074585\n",
      "Epoch 6, Loss: 1.7935371398925781\n",
      "Epoch 7, Loss: 1.888123869895935\n",
      "Epoch 8, Loss: 1.8637278079986572\n",
      "Epoch 9, Loss: 1.910657525062561\n",
      "Epoch 10, Loss: 2.261155843734741\n",
      "Epoch 11, Loss: 2.3682682514190674\n",
      "Epoch 12, Loss: 1.8338145017623901\n",
      "Epoch 13, Loss: 1.8538450002670288\n",
      "Epoch 14, Loss: 1.9725110530853271\n",
      "Epoch 15, Loss: 1.8662104606628418\n",
      "Epoch 16, Loss: 1.8077356815338135\n",
      "Epoch 17, Loss: 1.9653570652008057\n",
      "Epoch 18, Loss: 1.9070907831192017\n",
      "Epoch 19, Loss: 1.867520809173584\n",
      "Epoch 20, Loss: 1.7819446325302124\n",
      "Epoch 21, Loss: 1.9408841133117676\n",
      "Epoch 22, Loss: 1.8925601243972778\n",
      "Epoch 23, Loss: 1.842072606086731\n",
      "Epoch 24, Loss: 1.8588203191757202\n",
      "Epoch 25, Loss: 1.8640811443328857\n",
      "Epoch 26, Loss: 1.8186304569244385\n",
      "Epoch 27, Loss: 1.955135703086853\n",
      "Epoch 28, Loss: 1.9381393194198608\n",
      "Epoch 29, Loss: 1.8570717573165894\n",
      "Epoch 30, Loss: 1.9623407125473022\n",
      "Epoch 31, Loss: 1.7962597608566284\n",
      "Epoch 32, Loss: 1.881879448890686\n",
      "Epoch 33, Loss: 1.8938912153244019\n",
      "Epoch 34, Loss: 1.8690695762634277\n",
      "Epoch 35, Loss: 1.8540167808532715\n",
      "Epoch 36, Loss: 1.925658106803894\n",
      "Epoch 37, Loss: 1.8715299367904663\n",
      "Epoch 38, Loss: 1.7846720218658447\n",
      "Epoch 39, Loss: 1.7742502689361572\n",
      "Epoch 40, Loss: 1.7703373432159424\n",
      "Epoch 41, Loss: 1.8657041788101196\n",
      "Epoch 42, Loss: 1.8216285705566406\n",
      "Epoch 43, Loss: 1.7380355596542358\n",
      "Epoch 44, Loss: 1.9635359048843384\n",
      "Epoch 45, Loss: 1.8935348987579346\n",
      "Epoch 46, Loss: 2.001068353652954\n",
      "Epoch 47, Loss: 1.705028772354126\n",
      "Epoch 48, Loss: 1.9469830989837646\n",
      "Epoch 49, Loss: 1.850147008895874\n",
      "Epoch 50, Loss: 1.8445640802383423\n",
      "Validation Accuracy: 0.2540\n",
      "Validation accuracy: 0.25396825396825395\n",
      "Training with lr=0.001, hidden_sizes=[64, 128, 32], batch_size=64\n",
      "Epoch 1, Loss: 10.02698040008545\n",
      "Epoch 2, Loss: 3.0942015647888184\n",
      "Epoch 3, Loss: 2.299213409423828\n",
      "Epoch 4, Loss: 2.3081865310668945\n",
      "Epoch 5, Loss: 2.143749713897705\n",
      "Epoch 6, Loss: 2.059842586517334\n",
      "Epoch 7, Loss: 2.0083305835723877\n",
      "Epoch 8, Loss: 2.019277572631836\n",
      "Epoch 9, Loss: 1.93050217628479\n",
      "Epoch 10, Loss: 2.076063632965088\n",
      "Epoch 11, Loss: 1.9224979877471924\n",
      "Epoch 12, Loss: 1.9499353170394897\n",
      "Epoch 13, Loss: 2.0663552284240723\n",
      "Epoch 14, Loss: 1.9412988424301147\n",
      "Epoch 15, Loss: 1.9447386264801025\n",
      "Epoch 16, Loss: 1.8611667156219482\n",
      "Epoch 17, Loss: 1.9029271602630615\n",
      "Epoch 18, Loss: 1.8955878019332886\n",
      "Epoch 19, Loss: 1.948994755744934\n",
      "Epoch 20, Loss: 1.885787010192871\n",
      "Epoch 21, Loss: 1.8855657577514648\n",
      "Epoch 22, Loss: 2.0011401176452637\n",
      "Epoch 23, Loss: 1.874153971672058\n",
      "Epoch 24, Loss: 1.9115116596221924\n",
      "Epoch 25, Loss: 1.9567075967788696\n",
      "Epoch 26, Loss: 1.9552611112594604\n",
      "Epoch 27, Loss: 1.891790509223938\n",
      "Epoch 28, Loss: 1.8798580169677734\n",
      "Epoch 29, Loss: 1.932140588760376\n",
      "Epoch 30, Loss: 1.8787533044815063\n",
      "Epoch 31, Loss: 1.8987318277359009\n",
      "Epoch 32, Loss: 1.9235622882843018\n",
      "Epoch 33, Loss: 1.8866877555847168\n",
      "Epoch 34, Loss: 1.89376962184906\n",
      "Epoch 35, Loss: 1.914398193359375\n",
      "Epoch 36, Loss: 1.8746509552001953\n",
      "Epoch 37, Loss: 1.8916021585464478\n",
      "Epoch 38, Loss: 1.8668073415756226\n",
      "Epoch 39, Loss: 1.9548065662384033\n",
      "Epoch 40, Loss: 1.8767731189727783\n",
      "Epoch 41, Loss: 1.86184561252594\n",
      "Epoch 42, Loss: 1.949084997177124\n",
      "Epoch 43, Loss: 1.9019787311553955\n",
      "Epoch 44, Loss: 1.8700345754623413\n",
      "Epoch 45, Loss: 2.001533269882202\n",
      "Epoch 46, Loss: 1.8784570693969727\n",
      "Epoch 47, Loss: 1.9534274339675903\n",
      "Epoch 48, Loss: 1.872800588607788\n",
      "Epoch 49, Loss: 1.8239457607269287\n",
      "Epoch 50, Loss: 1.870661973953247\n",
      "Validation Accuracy: 0.1720\n",
      "Validation accuracy: 0.17195767195767195\n",
      "Training with lr=0.001, hidden_sizes=[64, 128, 32], batch_size=128\n",
      "Epoch 1, Loss: 16.153247833251953\n",
      "Epoch 2, Loss: 9.342426300048828\n",
      "Epoch 3, Loss: 4.435750484466553\n",
      "Epoch 4, Loss: 2.910219192504883\n",
      "Epoch 5, Loss: 2.950697422027588\n",
      "Epoch 6, Loss: 2.48209810256958\n",
      "Epoch 7, Loss: 2.227085828781128\n",
      "Epoch 8, Loss: 2.2386810779571533\n",
      "Epoch 9, Loss: 2.0634968280792236\n",
      "Epoch 10, Loss: 2.11894154548645\n",
      "Epoch 11, Loss: 2.0088610649108887\n",
      "Epoch 12, Loss: 1.937567949295044\n",
      "Epoch 13, Loss: 2.0496819019317627\n",
      "Epoch 14, Loss: 2.1181955337524414\n",
      "Epoch 15, Loss: 2.065368175506592\n",
      "Epoch 16, Loss: 1.9443429708480835\n",
      "Epoch 17, Loss: 2.0527186393737793\n",
      "Epoch 18, Loss: 1.89686918258667\n",
      "Epoch 19, Loss: 1.970223307609558\n",
      "Epoch 20, Loss: 1.9815208911895752\n",
      "Epoch 21, Loss: 1.9971593618392944\n",
      "Epoch 22, Loss: 1.9365180730819702\n",
      "Epoch 23, Loss: 1.9207656383514404\n",
      "Epoch 24, Loss: 1.9694464206695557\n",
      "Epoch 25, Loss: 1.916038155555725\n",
      "Epoch 26, Loss: 1.911525011062622\n",
      "Epoch 27, Loss: 1.9146877527236938\n",
      "Epoch 28, Loss: 1.980107307434082\n",
      "Epoch 29, Loss: 1.9372793436050415\n",
      "Epoch 30, Loss: 1.9518251419067383\n",
      "Epoch 31, Loss: 1.8989568948745728\n",
      "Epoch 32, Loss: 1.950674057006836\n",
      "Epoch 33, Loss: 1.9022148847579956\n",
      "Epoch 34, Loss: 1.9048874378204346\n",
      "Epoch 35, Loss: 1.932346224784851\n",
      "Epoch 36, Loss: 1.9116857051849365\n",
      "Epoch 37, Loss: 1.8794565200805664\n",
      "Epoch 38, Loss: 1.89678156375885\n",
      "Epoch 39, Loss: 1.9107884168624878\n",
      "Epoch 40, Loss: 1.9315582513809204\n",
      "Epoch 41, Loss: 1.892125129699707\n",
      "Epoch 42, Loss: 1.9232879877090454\n",
      "Epoch 43, Loss: 1.9057992696762085\n",
      "Epoch 44, Loss: 1.9208197593688965\n",
      "Epoch 45, Loss: 1.9097803831100464\n",
      "Epoch 46, Loss: 1.9141860008239746\n",
      "Epoch 47, Loss: 1.8847384452819824\n",
      "Epoch 48, Loss: 1.9054226875305176\n",
      "Epoch 49, Loss: 1.8853724002838135\n",
      "Epoch 50, Loss: 1.898036003112793\n",
      "Validation Accuracy: 0.1720\n",
      "Validation accuracy: 0.17195767195767195\n",
      "Training with lr=0.0005, hidden_sizes=[128, 64], batch_size=16\n",
      "Epoch 1, Loss: 18.734119415283203\n",
      "Epoch 2, Loss: 23.5393009185791\n",
      "Epoch 3, Loss: 10.591306686401367\n",
      "Epoch 4, Loss: 4.861237525939941\n",
      "Epoch 5, Loss: 4.562332630157471\n",
      "Epoch 6, Loss: 4.503997802734375\n",
      "Epoch 7, Loss: 4.059441089630127\n",
      "Epoch 8, Loss: 1.8993786573410034\n",
      "Epoch 9, Loss: 3.606518268585205\n",
      "Epoch 10, Loss: 2.0301172733306885\n",
      "Epoch 11, Loss: 2.514119863510132\n",
      "Epoch 12, Loss: 2.2041850090026855\n",
      "Epoch 13, Loss: 1.6220659017562866\n",
      "Epoch 14, Loss: 1.8887722492218018\n",
      "Epoch 15, Loss: 2.2401235103607178\n",
      "Epoch 16, Loss: 1.8213220834732056\n",
      "Epoch 17, Loss: 1.7273331880569458\n",
      "Epoch 18, Loss: 1.8022862672805786\n",
      "Epoch 19, Loss: 2.2481682300567627\n",
      "Epoch 20, Loss: 1.856745958328247\n",
      "Epoch 21, Loss: 1.8970061540603638\n",
      "Epoch 22, Loss: 1.8788591623306274\n",
      "Epoch 23, Loss: 1.7426090240478516\n",
      "Epoch 24, Loss: 2.2192184925079346\n",
      "Epoch 25, Loss: 1.73491370677948\n",
      "Epoch 26, Loss: 2.132049798965454\n",
      "Epoch 27, Loss: 2.3826022148132324\n",
      "Epoch 28, Loss: 1.8996994495391846\n",
      "Epoch 29, Loss: 1.9220919609069824\n",
      "Epoch 30, Loss: 1.6983435153961182\n",
      "Epoch 31, Loss: 1.6447192430496216\n",
      "Epoch 32, Loss: 2.1267173290252686\n",
      "Epoch 33, Loss: 1.7051595449447632\n",
      "Epoch 34, Loss: 1.8595050573349\n",
      "Epoch 35, Loss: 1.677582025527954\n",
      "Epoch 36, Loss: 2.387817859649658\n",
      "Epoch 37, Loss: 1.7370069026947021\n",
      "Epoch 38, Loss: 2.1437759399414062\n",
      "Epoch 39, Loss: 1.7357815504074097\n",
      "Epoch 40, Loss: 1.6776776313781738\n",
      "Epoch 41, Loss: 1.773106336593628\n",
      "Epoch 42, Loss: 1.7636058330535889\n",
      "Epoch 43, Loss: 1.7916450500488281\n",
      "Epoch 44, Loss: 1.834945559501648\n",
      "Epoch 45, Loss: 1.7368687391281128\n",
      "Epoch 46, Loss: 1.8494430780410767\n",
      "Epoch 47, Loss: 1.7476210594177246\n",
      "Epoch 48, Loss: 1.8214925527572632\n",
      "Epoch 49, Loss: 2.034921407699585\n",
      "Epoch 50, Loss: 1.7829489707946777\n",
      "Validation Accuracy: 0.2540\n",
      "Validation accuracy: 0.25396825396825395\n",
      "Training with lr=0.0005, hidden_sizes=[128, 64], batch_size=32\n",
      "Epoch 1, Loss: 31.75391387939453\n",
      "Epoch 2, Loss: 22.9351806640625\n",
      "Epoch 3, Loss: 6.37828254699707\n",
      "Epoch 4, Loss: 23.076160430908203\n",
      "Epoch 5, Loss: 9.30024242401123\n",
      "Epoch 6, Loss: 3.654165744781494\n",
      "Epoch 7, Loss: 4.302675724029541\n",
      "Epoch 8, Loss: 3.954712390899658\n",
      "Epoch 9, Loss: 3.7770426273345947\n",
      "Epoch 10, Loss: 2.3790764808654785\n",
      "Epoch 11, Loss: 2.5842249393463135\n",
      "Epoch 12, Loss: 2.451585054397583\n",
      "Epoch 13, Loss: 3.1918578147888184\n",
      "Epoch 14, Loss: 2.296793222427368\n",
      "Epoch 15, Loss: 3.175588369369507\n",
      "Epoch 16, Loss: 2.0800797939300537\n",
      "Epoch 17, Loss: 2.1578550338745117\n",
      "Epoch 18, Loss: 2.0267844200134277\n",
      "Epoch 19, Loss: 1.8463202714920044\n",
      "Epoch 20, Loss: 1.8393281698226929\n",
      "Epoch 21, Loss: 1.7571278810501099\n",
      "Epoch 22, Loss: 2.117243528366089\n",
      "Epoch 23, Loss: 2.109182834625244\n",
      "Epoch 24, Loss: 2.0246853828430176\n",
      "Epoch 25, Loss: 2.0165679454803467\n",
      "Epoch 26, Loss: 1.9016480445861816\n",
      "Epoch 27, Loss: 1.652418851852417\n",
      "Epoch 28, Loss: 1.9413292407989502\n",
      "Epoch 29, Loss: 1.8341411352157593\n",
      "Epoch 30, Loss: 1.7297303676605225\n",
      "Epoch 31, Loss: 2.5575177669525146\n",
      "Epoch 32, Loss: 1.867791771888733\n",
      "Epoch 33, Loss: 1.6039882898330688\n",
      "Epoch 34, Loss: 1.7716596126556396\n",
      "Epoch 35, Loss: 1.9032635688781738\n",
      "Epoch 36, Loss: 1.7280160188674927\n",
      "Epoch 37, Loss: 1.6621384620666504\n",
      "Epoch 38, Loss: 1.6211603879928589\n",
      "Epoch 39, Loss: 1.7022148370742798\n",
      "Epoch 40, Loss: 1.761061191558838\n",
      "Epoch 41, Loss: 1.692875623703003\n",
      "Epoch 42, Loss: 1.9193016290664673\n",
      "Epoch 43, Loss: 1.7152187824249268\n",
      "Epoch 44, Loss: 1.6464134454727173\n",
      "Epoch 45, Loss: 2.119450569152832\n",
      "Epoch 46, Loss: 1.8712846040725708\n",
      "Epoch 47, Loss: 1.928158164024353\n",
      "Epoch 48, Loss: 1.822971224784851\n",
      "Epoch 49, Loss: 1.82249116897583\n",
      "Epoch 50, Loss: 1.8078118562698364\n",
      "Validation Accuracy: 0.2566\n",
      "Validation accuracy: 0.2566137566137566\n",
      "Training with lr=0.0005, hidden_sizes=[128, 64], batch_size=64\n",
      "Epoch 1, Loss: 32.66242599487305\n",
      "Epoch 2, Loss: 29.532018661499023\n",
      "Epoch 3, Loss: 24.48752212524414\n",
      "Epoch 4, Loss: 21.498830795288086\n",
      "Epoch 5, Loss: 12.902780532836914\n",
      "Epoch 6, Loss: 9.683159828186035\n",
      "Epoch 7, Loss: 8.907713890075684\n",
      "Epoch 8, Loss: 7.210801124572754\n",
      "Epoch 9, Loss: 4.0263800621032715\n",
      "Epoch 10, Loss: 4.318844318389893\n",
      "Epoch 11, Loss: 3.6276915073394775\n",
      "Epoch 12, Loss: 3.195781946182251\n",
      "Epoch 13, Loss: 3.2655792236328125\n",
      "Epoch 14, Loss: 4.293503761291504\n",
      "Epoch 15, Loss: 3.1085944175720215\n",
      "Epoch 16, Loss: 2.7274069786071777\n",
      "Epoch 17, Loss: 2.760185718536377\n",
      "Epoch 18, Loss: 2.38492751121521\n",
      "Epoch 19, Loss: 2.327575922012329\n",
      "Epoch 20, Loss: 2.2798869609832764\n",
      "Epoch 21, Loss: 2.1625142097473145\n",
      "Epoch 22, Loss: 2.330068349838257\n",
      "Epoch 23, Loss: 2.198918342590332\n",
      "Epoch 24, Loss: 1.8954520225524902\n",
      "Epoch 25, Loss: 2.1098380088806152\n",
      "Epoch 26, Loss: 2.255096673965454\n",
      "Epoch 27, Loss: 2.2021262645721436\n",
      "Epoch 28, Loss: 2.0640459060668945\n",
      "Epoch 29, Loss: 2.1053073406219482\n",
      "Epoch 30, Loss: 2.282679796218872\n",
      "Epoch 31, Loss: 2.063707113265991\n",
      "Epoch 32, Loss: 1.8566913604736328\n",
      "Epoch 33, Loss: 1.7842639684677124\n",
      "Epoch 34, Loss: 1.9227848052978516\n",
      "Epoch 35, Loss: 1.8335081338882446\n",
      "Epoch 36, Loss: 2.1049740314483643\n",
      "Epoch 37, Loss: 2.2618370056152344\n",
      "Epoch 38, Loss: 1.8347563743591309\n",
      "Epoch 39, Loss: 1.9145755767822266\n",
      "Epoch 40, Loss: 1.9569491147994995\n",
      "Epoch 41, Loss: 1.7965742349624634\n",
      "Epoch 42, Loss: 1.9136865139007568\n",
      "Epoch 43, Loss: 1.8902130126953125\n",
      "Epoch 44, Loss: 1.8552093505859375\n",
      "Epoch 45, Loss: 1.8317623138427734\n",
      "Epoch 46, Loss: 1.9120469093322754\n",
      "Epoch 47, Loss: 1.92865788936615\n",
      "Epoch 48, Loss: 1.8218644857406616\n",
      "Epoch 49, Loss: 1.827535629272461\n",
      "Epoch 50, Loss: 1.7028089761734009\n",
      "Validation Accuracy: 0.2275\n",
      "Validation accuracy: 0.2275132275132275\n",
      "Training with lr=0.0005, hidden_sizes=[128, 64], batch_size=128\n",
      "Epoch 1, Loss: 43.96783447265625\n",
      "Epoch 2, Loss: 38.2487678527832\n",
      "Epoch 3, Loss: 23.87380599975586\n",
      "Epoch 4, Loss: 25.18053436279297\n",
      "Epoch 5, Loss: 20.748638153076172\n",
      "Epoch 6, Loss: 17.149259567260742\n",
      "Epoch 7, Loss: 15.925710678100586\n",
      "Epoch 8, Loss: 13.402429580688477\n",
      "Epoch 9, Loss: 13.011616706848145\n",
      "Epoch 10, Loss: 9.062682151794434\n",
      "Epoch 11, Loss: 7.215905666351318\n",
      "Epoch 12, Loss: 7.629343032836914\n",
      "Epoch 13, Loss: 6.883809566497803\n",
      "Epoch 14, Loss: 4.6822123527526855\n",
      "Epoch 15, Loss: 4.951412677764893\n",
      "Epoch 16, Loss: 4.372696876525879\n",
      "Epoch 17, Loss: 4.2808709144592285\n",
      "Epoch 18, Loss: 4.605579853057861\n",
      "Epoch 19, Loss: 3.888338088989258\n",
      "Epoch 20, Loss: 3.1863675117492676\n",
      "Epoch 21, Loss: 2.8390090465545654\n",
      "Epoch 22, Loss: 3.130709648132324\n",
      "Epoch 23, Loss: 3.0641229152679443\n",
      "Epoch 24, Loss: 2.578625440597534\n",
      "Epoch 25, Loss: 2.4374544620513916\n",
      "Epoch 26, Loss: 2.7213382720947266\n",
      "Epoch 27, Loss: 2.3148207664489746\n",
      "Epoch 28, Loss: 2.4731626510620117\n",
      "Epoch 29, Loss: 2.24280047416687\n",
      "Epoch 30, Loss: 2.3484690189361572\n",
      "Epoch 31, Loss: 2.609341621398926\n",
      "Epoch 32, Loss: 2.2533063888549805\n",
      "Epoch 33, Loss: 2.2062296867370605\n",
      "Epoch 34, Loss: 2.4834096431732178\n",
      "Epoch 35, Loss: 2.22172474861145\n",
      "Epoch 36, Loss: 2.050330877304077\n",
      "Epoch 37, Loss: 1.9919450283050537\n",
      "Epoch 38, Loss: 2.1070592403411865\n",
      "Epoch 39, Loss: 2.1264991760253906\n",
      "Epoch 40, Loss: 2.135485887527466\n",
      "Epoch 41, Loss: 2.230477809906006\n",
      "Epoch 42, Loss: 2.018505334854126\n",
      "Epoch 43, Loss: 1.9660907983779907\n",
      "Epoch 44, Loss: 2.308964252471924\n",
      "Epoch 45, Loss: 2.300626277923584\n",
      "Epoch 46, Loss: 2.2423508167266846\n",
      "Epoch 47, Loss: 2.1077873706817627\n",
      "Epoch 48, Loss: 2.062490463256836\n",
      "Epoch 49, Loss: 1.9441680908203125\n",
      "Epoch 50, Loss: 2.0877695083618164\n",
      "Validation Accuracy: 0.2090\n",
      "Validation accuracy: 0.20899470899470898\n",
      "Training with lr=0.0005, hidden_sizes=[128, 64, 32], batch_size=16\n",
      "Epoch 1, Loss: 6.95536470413208\n",
      "Epoch 2, Loss: 4.697364330291748\n",
      "Epoch 3, Loss: 4.180920124053955\n",
      "Epoch 4, Loss: 2.796246290206909\n",
      "Epoch 5, Loss: 3.058506965637207\n",
      "Epoch 6, Loss: 2.06695556640625\n",
      "Epoch 7, Loss: 2.1163201332092285\n",
      "Epoch 8, Loss: 2.430520534515381\n",
      "Epoch 9, Loss: 1.9537018537521362\n",
      "Epoch 10, Loss: 1.944692611694336\n",
      "Epoch 11, Loss: 1.9423449039459229\n",
      "Epoch 12, Loss: 1.902840495109558\n",
      "Epoch 13, Loss: 1.890208125114441\n",
      "Epoch 14, Loss: 1.8143867254257202\n",
      "Epoch 15, Loss: 1.9332412481307983\n",
      "Epoch 16, Loss: 2.0780065059661865\n",
      "Epoch 17, Loss: 1.7930294275283813\n",
      "Epoch 18, Loss: 1.8735977411270142\n",
      "Epoch 19, Loss: 2.138584613800049\n",
      "Epoch 20, Loss: 1.9000544548034668\n",
      "Epoch 21, Loss: 1.885857105255127\n",
      "Epoch 22, Loss: 1.8453091382980347\n",
      "Epoch 23, Loss: 1.9326454401016235\n",
      "Epoch 24, Loss: 1.7660151720046997\n",
      "Epoch 25, Loss: 1.9706652164459229\n",
      "Epoch 26, Loss: 1.9148802757263184\n",
      "Epoch 27, Loss: 1.9048702716827393\n",
      "Epoch 28, Loss: 1.770437240600586\n",
      "Epoch 29, Loss: 1.9171812534332275\n",
      "Epoch 30, Loss: 2.1159260272979736\n",
      "Epoch 31, Loss: 1.8628088235855103\n",
      "Epoch 32, Loss: 1.7844301462173462\n",
      "Epoch 33, Loss: 2.083281993865967\n",
      "Epoch 34, Loss: 1.9988054037094116\n",
      "Epoch 35, Loss: 1.95633065700531\n",
      "Epoch 36, Loss: 1.7065006494522095\n",
      "Epoch 37, Loss: 1.9085043668746948\n",
      "Epoch 38, Loss: 1.6999787092208862\n",
      "Epoch 39, Loss: 1.788787841796875\n",
      "Epoch 40, Loss: 1.7943974733352661\n",
      "Epoch 41, Loss: 1.7848320007324219\n",
      "Epoch 42, Loss: 1.6956740617752075\n",
      "Epoch 43, Loss: 1.8436092138290405\n",
      "Epoch 44, Loss: 1.8349889516830444\n",
      "Epoch 45, Loss: 2.0204966068267822\n",
      "Epoch 46, Loss: 1.7738772630691528\n",
      "Epoch 47, Loss: 1.8852547407150269\n",
      "Epoch 48, Loss: 1.727866530418396\n",
      "Epoch 49, Loss: 1.8995896577835083\n",
      "Epoch 50, Loss: 1.5908191204071045\n",
      "Validation Accuracy: 0.2884\n",
      "Validation accuracy: 0.28835978835978837\n",
      "Training with lr=0.0005, hidden_sizes=[128, 64, 32], batch_size=32\n",
      "Epoch 1, Loss: 15.172249794006348\n",
      "Epoch 2, Loss: 9.835809707641602\n",
      "Epoch 3, Loss: 4.6972503662109375\n",
      "Epoch 4, Loss: 5.792296886444092\n",
      "Epoch 5, Loss: 3.355924367904663\n",
      "Epoch 6, Loss: 5.523142337799072\n",
      "Epoch 7, Loss: 3.336487054824829\n",
      "Epoch 8, Loss: 3.265674591064453\n",
      "Epoch 9, Loss: 2.724722146987915\n",
      "Epoch 10, Loss: 2.7992970943450928\n",
      "Epoch 11, Loss: 2.8075318336486816\n",
      "Epoch 12, Loss: 1.9761933088302612\n",
      "Epoch 13, Loss: 1.9825453758239746\n",
      "Epoch 14, Loss: 2.0169930458068848\n",
      "Epoch 15, Loss: 2.1509969234466553\n",
      "Epoch 16, Loss: 3.0801146030426025\n",
      "Epoch 17, Loss: 1.9160301685333252\n",
      "Epoch 18, Loss: 1.8802458047866821\n",
      "Epoch 19, Loss: 2.0724215507507324\n",
      "Epoch 20, Loss: 1.9101094007492065\n",
      "Epoch 21, Loss: 2.1084280014038086\n",
      "Epoch 22, Loss: 1.8793550729751587\n",
      "Epoch 23, Loss: 2.1557610034942627\n",
      "Epoch 24, Loss: 2.075099468231201\n",
      "Epoch 25, Loss: 1.8753803968429565\n",
      "Epoch 26, Loss: 1.878798007965088\n",
      "Epoch 27, Loss: 2.1947274208068848\n",
      "Epoch 28, Loss: 2.0500295162200928\n",
      "Epoch 29, Loss: 1.9378057718276978\n",
      "Epoch 30, Loss: 1.8436920642852783\n",
      "Epoch 31, Loss: 1.9192585945129395\n",
      "Epoch 32, Loss: 1.7994638681411743\n",
      "Epoch 33, Loss: 1.9982234239578247\n",
      "Epoch 34, Loss: 1.8733012676239014\n",
      "Epoch 35, Loss: 1.8352495431900024\n",
      "Epoch 36, Loss: 1.965242862701416\n",
      "Epoch 37, Loss: 2.0244362354278564\n",
      "Epoch 38, Loss: 1.9254120588302612\n",
      "Epoch 39, Loss: 1.8950693607330322\n",
      "Epoch 40, Loss: 1.8150941133499146\n",
      "Epoch 41, Loss: 2.0669174194335938\n",
      "Epoch 42, Loss: 2.0808568000793457\n",
      "Epoch 43, Loss: 1.8100892305374146\n",
      "Epoch 44, Loss: 1.829879879951477\n",
      "Epoch 45, Loss: 1.9053984880447388\n",
      "Epoch 46, Loss: 2.149736166000366\n",
      "Epoch 47, Loss: 1.943750023841858\n",
      "Epoch 48, Loss: 1.8258944749832153\n",
      "Epoch 49, Loss: 1.9503422975540161\n",
      "Epoch 50, Loss: 1.9426213502883911\n",
      "Validation Accuracy: 0.2593\n",
      "Validation accuracy: 0.25925925925925924\n",
      "Training with lr=0.0005, hidden_sizes=[128, 64, 32], batch_size=64\n",
      "Epoch 1, Loss: 19.8032169342041\n",
      "Epoch 2, Loss: 11.062644004821777\n",
      "Epoch 3, Loss: 8.95513916015625\n",
      "Epoch 4, Loss: 6.074990272521973\n",
      "Epoch 5, Loss: 6.723183631896973\n",
      "Epoch 6, Loss: 5.7998857498168945\n",
      "Epoch 7, Loss: 4.048309326171875\n",
      "Epoch 8, Loss: 3.284921884536743\n",
      "Epoch 9, Loss: 3.749347448348999\n",
      "Epoch 10, Loss: 2.9637839794158936\n",
      "Epoch 11, Loss: 3.127089738845825\n",
      "Epoch 12, Loss: 2.909912109375\n",
      "Epoch 13, Loss: 2.34407639503479\n",
      "Epoch 14, Loss: 2.3182406425476074\n",
      "Epoch 15, Loss: 2.186321496963501\n",
      "Epoch 16, Loss: 2.009782314300537\n",
      "Epoch 17, Loss: 2.2577946186065674\n",
      "Epoch 18, Loss: 2.1120047569274902\n",
      "Epoch 19, Loss: 2.08331036567688\n",
      "Epoch 20, Loss: 2.1661787033081055\n",
      "Epoch 21, Loss: 2.311702013015747\n",
      "Epoch 22, Loss: 1.9653143882751465\n",
      "Epoch 23, Loss: 1.868070363998413\n",
      "Epoch 24, Loss: 1.8709583282470703\n",
      "Epoch 25, Loss: 2.340092182159424\n",
      "Epoch 26, Loss: 1.939353585243225\n",
      "Epoch 27, Loss: 2.161006212234497\n",
      "Epoch 28, Loss: 2.096999406814575\n",
      "Epoch 29, Loss: 2.0431907176971436\n",
      "Epoch 30, Loss: 1.9660531282424927\n",
      "Epoch 31, Loss: 1.9276373386383057\n",
      "Epoch 32, Loss: 2.017209768295288\n",
      "Epoch 33, Loss: 1.9550930261611938\n",
      "Epoch 34, Loss: 1.9583975076675415\n",
      "Epoch 35, Loss: 1.9590392112731934\n",
      "Epoch 36, Loss: 1.964202880859375\n",
      "Epoch 37, Loss: 1.8957375288009644\n",
      "Epoch 38, Loss: 1.8769032955169678\n",
      "Epoch 39, Loss: 1.9032809734344482\n",
      "Epoch 40, Loss: 1.8855414390563965\n",
      "Epoch 41, Loss: 1.9772332906723022\n",
      "Epoch 42, Loss: 1.9483633041381836\n",
      "Epoch 43, Loss: 1.9299663305282593\n",
      "Epoch 44, Loss: 1.9429227113723755\n",
      "Epoch 45, Loss: 1.9941405057907104\n",
      "Epoch 46, Loss: 1.8665659427642822\n",
      "Epoch 47, Loss: 1.81659734249115\n",
      "Epoch 48, Loss: 1.9141895771026611\n",
      "Epoch 49, Loss: 1.9279946088790894\n",
      "Epoch 50, Loss: 1.851881504058838\n",
      "Validation Accuracy: 0.1587\n",
      "Validation accuracy: 0.15873015873015872\n",
      "Training with lr=0.0005, hidden_sizes=[128, 64, 32], batch_size=128\n",
      "Epoch 1, Loss: 20.041990280151367\n",
      "Epoch 2, Loss: 15.583892822265625\n",
      "Epoch 3, Loss: 12.210173606872559\n",
      "Epoch 4, Loss: 11.369129180908203\n",
      "Epoch 5, Loss: 8.882384300231934\n",
      "Epoch 6, Loss: 6.699132919311523\n",
      "Epoch 7, Loss: 5.024658679962158\n",
      "Epoch 8, Loss: 5.265800476074219\n",
      "Epoch 9, Loss: 5.01788330078125\n",
      "Epoch 10, Loss: 5.021493911743164\n",
      "Epoch 11, Loss: 4.06996488571167\n",
      "Epoch 12, Loss: 2.976970672607422\n",
      "Epoch 13, Loss: 2.793471097946167\n",
      "Epoch 14, Loss: 3.807642936706543\n",
      "Epoch 15, Loss: 2.57692813873291\n",
      "Epoch 16, Loss: 2.5939557552337646\n",
      "Epoch 17, Loss: 2.4876198768615723\n",
      "Epoch 18, Loss: 2.653592586517334\n",
      "Epoch 19, Loss: 3.130749225616455\n",
      "Epoch 20, Loss: 2.4152281284332275\n",
      "Epoch 21, Loss: 2.3470513820648193\n",
      "Epoch 22, Loss: 2.716485023498535\n",
      "Epoch 23, Loss: 2.288985013961792\n",
      "Epoch 24, Loss: 2.3983750343322754\n",
      "Epoch 25, Loss: 2.1706926822662354\n",
      "Epoch 26, Loss: 2.5192320346832275\n",
      "Epoch 27, Loss: 1.9768022298812866\n",
      "Epoch 28, Loss: 2.23860239982605\n",
      "Epoch 29, Loss: 1.9890358448028564\n",
      "Epoch 30, Loss: 2.059985876083374\n",
      "Epoch 31, Loss: 2.1523234844207764\n",
      "Epoch 32, Loss: 2.2493011951446533\n",
      "Epoch 33, Loss: 1.9919919967651367\n",
      "Epoch 34, Loss: 2.3031821250915527\n",
      "Epoch 35, Loss: 1.9974133968353271\n",
      "Epoch 36, Loss: 2.0131680965423584\n",
      "Epoch 37, Loss: 2.238394021987915\n",
      "Epoch 38, Loss: 1.987934947013855\n",
      "Epoch 39, Loss: 2.13323712348938\n",
      "Epoch 40, Loss: 2.2208025455474854\n",
      "Epoch 41, Loss: 1.943087100982666\n",
      "Epoch 42, Loss: 1.9978549480438232\n",
      "Epoch 43, Loss: 1.9563888311386108\n",
      "Epoch 44, Loss: 2.0330233573913574\n",
      "Epoch 45, Loss: 1.915993571281433\n",
      "Epoch 46, Loss: 2.081310510635376\n",
      "Epoch 47, Loss: 1.993911862373352\n",
      "Epoch 48, Loss: 1.9315518140792847\n",
      "Epoch 49, Loss: 2.0427279472351074\n",
      "Epoch 50, Loss: 2.0163776874542236\n",
      "Validation Accuracy: 0.1587\n",
      "Validation accuracy: 0.15873015873015872\n",
      "Training with lr=0.0005, hidden_sizes=[128, 64, 32, 16], batch_size=16\n",
      "Epoch 1, Loss: 4.207644939422607\n",
      "Epoch 2, Loss: 2.7330446243286133\n",
      "Epoch 3, Loss: 3.2062954902648926\n",
      "Epoch 4, Loss: 2.3388545513153076\n",
      "Epoch 5, Loss: 2.292422294616699\n",
      "Epoch 6, Loss: 2.9147088527679443\n",
      "Epoch 7, Loss: 2.0461058616638184\n",
      "Epoch 8, Loss: 2.1067004203796387\n",
      "Epoch 9, Loss: 2.1223013401031494\n",
      "Epoch 10, Loss: 2.345315456390381\n",
      "Epoch 11, Loss: 2.1061911582946777\n",
      "Epoch 12, Loss: 2.4067108631134033\n",
      "Epoch 13, Loss: 2.083697557449341\n",
      "Epoch 14, Loss: 1.9623520374298096\n",
      "Epoch 15, Loss: 1.8668795824050903\n",
      "Epoch 16, Loss: 1.9825233221054077\n",
      "Epoch 17, Loss: 1.8030601739883423\n",
      "Epoch 18, Loss: 1.879198431968689\n",
      "Epoch 19, Loss: 2.036285638809204\n",
      "Epoch 20, Loss: 2.008957862854004\n",
      "Epoch 21, Loss: 1.7983291149139404\n",
      "Epoch 22, Loss: 1.970971703529358\n",
      "Epoch 23, Loss: 1.9220860004425049\n",
      "Epoch 24, Loss: 1.8704488277435303\n",
      "Epoch 25, Loss: 1.8106292486190796\n",
      "Epoch 26, Loss: 1.8325996398925781\n",
      "Epoch 27, Loss: 1.7430195808410645\n",
      "Epoch 28, Loss: 1.8060752153396606\n",
      "Epoch 29, Loss: 2.1408565044403076\n",
      "Epoch 30, Loss: 1.832208275794983\n",
      "Epoch 31, Loss: 1.941296100616455\n",
      "Epoch 32, Loss: 1.8681845664978027\n",
      "Epoch 33, Loss: 1.9436688423156738\n",
      "Epoch 34, Loss: 1.853066086769104\n",
      "Epoch 35, Loss: 1.9279509782791138\n",
      "Epoch 36, Loss: 1.9122575521469116\n",
      "Epoch 37, Loss: 2.170243978500366\n",
      "Epoch 38, Loss: 1.9197081327438354\n",
      "Epoch 39, Loss: 1.9186006784439087\n",
      "Epoch 40, Loss: 1.9929919242858887\n",
      "Epoch 41, Loss: 1.7524079084396362\n",
      "Epoch 42, Loss: 1.9528143405914307\n",
      "Epoch 43, Loss: 1.7889381647109985\n",
      "Epoch 44, Loss: 1.850762128829956\n",
      "Epoch 45, Loss: 1.7960231304168701\n",
      "Epoch 46, Loss: 1.8226486444473267\n",
      "Epoch 47, Loss: 1.8009419441223145\n",
      "Epoch 48, Loss: 1.8577314615249634\n",
      "Epoch 49, Loss: 1.9220569133758545\n",
      "Epoch 50, Loss: 1.9235763549804688\n",
      "Validation Accuracy: 0.1640\n",
      "Validation accuracy: 0.164021164021164\n",
      "Training with lr=0.0005, hidden_sizes=[128, 64, 32, 16], batch_size=32\n",
      "Epoch 1, Loss: 5.540318489074707\n",
      "Epoch 2, Loss: 5.921844959259033\n",
      "Epoch 3, Loss: 2.054717540740967\n",
      "Epoch 4, Loss: 2.9763216972351074\n",
      "Epoch 5, Loss: 2.6247687339782715\n",
      "Epoch 6, Loss: 2.5178275108337402\n",
      "Epoch 7, Loss: 3.900465965270996\n",
      "Epoch 8, Loss: 2.319847345352173\n",
      "Epoch 9, Loss: 2.077359914779663\n",
      "Epoch 10, Loss: 1.8842158317565918\n",
      "Epoch 11, Loss: 2.120380401611328\n",
      "Epoch 12, Loss: 2.0163207054138184\n",
      "Epoch 13, Loss: 2.0573933124542236\n",
      "Epoch 14, Loss: 1.9138706922531128\n",
      "Epoch 15, Loss: 2.0546364784240723\n",
      "Epoch 16, Loss: 1.8981660604476929\n",
      "Epoch 17, Loss: 2.025714635848999\n",
      "Epoch 18, Loss: 2.06367564201355\n",
      "Epoch 19, Loss: 1.9283734560012817\n",
      "Epoch 20, Loss: 1.9297370910644531\n",
      "Epoch 21, Loss: 2.0918939113616943\n",
      "Epoch 22, Loss: 1.9139862060546875\n",
      "Epoch 23, Loss: 1.8395692110061646\n",
      "Epoch 24, Loss: 2.0806386470794678\n",
      "Epoch 25, Loss: 1.9927047491073608\n",
      "Epoch 26, Loss: 2.0515944957733154\n",
      "Epoch 27, Loss: 2.008359670639038\n",
      "Epoch 28, Loss: 1.8640507459640503\n",
      "Epoch 29, Loss: 1.9050426483154297\n",
      "Epoch 30, Loss: 1.928389310836792\n",
      "Epoch 31, Loss: 1.9349095821380615\n",
      "Epoch 32, Loss: 1.9455710649490356\n",
      "Epoch 33, Loss: 1.8528721332550049\n",
      "Epoch 34, Loss: 1.938315510749817\n",
      "Epoch 35, Loss: 1.8766684532165527\n",
      "Epoch 36, Loss: 1.8413293361663818\n",
      "Epoch 37, Loss: 1.8739852905273438\n",
      "Epoch 38, Loss: 1.877137303352356\n",
      "Epoch 39, Loss: 1.8665372133255005\n",
      "Epoch 40, Loss: 1.8678975105285645\n",
      "Epoch 41, Loss: 1.9365335702896118\n",
      "Epoch 42, Loss: 1.9710276126861572\n",
      "Epoch 43, Loss: 1.8434184789657593\n",
      "Epoch 44, Loss: 1.835004448890686\n",
      "Epoch 45, Loss: 1.9841598272323608\n",
      "Epoch 46, Loss: 1.9368650913238525\n",
      "Epoch 47, Loss: 1.774666428565979\n",
      "Epoch 48, Loss: 1.8983467817306519\n",
      "Epoch 49, Loss: 2.189645290374756\n",
      "Epoch 50, Loss: 2.0053670406341553\n",
      "Validation Accuracy: 0.1587\n",
      "Validation accuracy: 0.15873015873015872\n",
      "Training with lr=0.0005, hidden_sizes=[128, 64, 32, 16], batch_size=64\n",
      "Epoch 1, Loss: 7.592371463775635\n",
      "Epoch 2, Loss: 5.805604457855225\n",
      "Epoch 3, Loss: 3.6362271308898926\n",
      "Epoch 4, Loss: 2.5405945777893066\n",
      "Epoch 5, Loss: 3.0673999786376953\n",
      "Epoch 6, Loss: 2.4690914154052734\n",
      "Epoch 7, Loss: 2.4589476585388184\n",
      "Epoch 8, Loss: 2.933300256729126\n",
      "Epoch 9, Loss: 2.2992279529571533\n",
      "Epoch 10, Loss: 2.0750958919525146\n",
      "Epoch 11, Loss: 2.105699062347412\n",
      "Epoch 12, Loss: 2.014888286590576\n",
      "Epoch 13, Loss: 2.2238199710845947\n",
      "Epoch 14, Loss: 2.009183168411255\n",
      "Epoch 15, Loss: 2.0835020542144775\n",
      "Epoch 16, Loss: 2.0905473232269287\n",
      "Epoch 17, Loss: 2.0309715270996094\n",
      "Epoch 18, Loss: 1.9587267637252808\n",
      "Epoch 19, Loss: 1.9108315706253052\n",
      "Epoch 20, Loss: 1.9371659755706787\n",
      "Epoch 21, Loss: 1.9742720127105713\n",
      "Epoch 22, Loss: 1.9521653652191162\n",
      "Epoch 23, Loss: 1.9547239542007446\n",
      "Epoch 24, Loss: 2.0630195140838623\n",
      "Epoch 25, Loss: 1.9520900249481201\n",
      "Epoch 26, Loss: 2.154539108276367\n",
      "Epoch 27, Loss: 1.934505581855774\n",
      "Epoch 28, Loss: 1.9636013507843018\n",
      "Epoch 29, Loss: 1.8072803020477295\n",
      "Epoch 30, Loss: 1.895321249961853\n",
      "Epoch 31, Loss: 1.960896611213684\n",
      "Epoch 32, Loss: 1.8644928932189941\n",
      "Epoch 33, Loss: 1.9071763753890991\n",
      "Epoch 34, Loss: 1.9282275438308716\n",
      "Epoch 35, Loss: 2.0206685066223145\n",
      "Epoch 36, Loss: 1.9164634943008423\n",
      "Epoch 37, Loss: 1.9265377521514893\n",
      "Epoch 38, Loss: 2.051345109939575\n",
      "Epoch 39, Loss: 1.8935465812683105\n",
      "Epoch 40, Loss: 1.9779982566833496\n",
      "Epoch 41, Loss: 1.8793245553970337\n",
      "Epoch 42, Loss: 1.8339139223098755\n",
      "Epoch 43, Loss: 1.888067364692688\n",
      "Epoch 44, Loss: 1.9067796468734741\n",
      "Epoch 45, Loss: 1.9148571491241455\n",
      "Epoch 46, Loss: 1.7880682945251465\n",
      "Epoch 47, Loss: 1.8519304990768433\n",
      "Epoch 48, Loss: 1.8490883111953735\n",
      "Epoch 49, Loss: 1.9370440244674683\n",
      "Epoch 50, Loss: 1.8845523595809937\n",
      "Validation Accuracy: 0.2646\n",
      "Validation accuracy: 0.26455026455026454\n",
      "Training with lr=0.0005, hidden_sizes=[128, 64, 32, 16], batch_size=128\n",
      "Epoch 1, Loss: 14.785879135131836\n",
      "Epoch 2, Loss: 9.966146469116211\n",
      "Epoch 3, Loss: 8.854839324951172\n",
      "Epoch 4, Loss: 5.3151164054870605\n",
      "Epoch 5, Loss: 5.822789192199707\n",
      "Epoch 6, Loss: 4.787079334259033\n",
      "Epoch 7, Loss: 3.2290003299713135\n",
      "Epoch 8, Loss: 3.551361083984375\n",
      "Epoch 9, Loss: 3.8770980834960938\n",
      "Epoch 10, Loss: 3.6144189834594727\n",
      "Epoch 11, Loss: 2.912513017654419\n",
      "Epoch 12, Loss: 3.320356845855713\n",
      "Epoch 13, Loss: 2.6968624591827393\n",
      "Epoch 14, Loss: 2.711641550064087\n",
      "Epoch 15, Loss: 2.8753232955932617\n",
      "Epoch 16, Loss: 2.716634750366211\n",
      "Epoch 17, Loss: 2.4348795413970947\n",
      "Epoch 18, Loss: 2.571167469024658\n",
      "Epoch 19, Loss: 2.422060012817383\n",
      "Epoch 20, Loss: 2.456458568572998\n",
      "Epoch 21, Loss: 2.5214362144470215\n",
      "Epoch 22, Loss: 2.2350103855133057\n",
      "Epoch 23, Loss: 2.3382768630981445\n",
      "Epoch 24, Loss: 2.2383267879486084\n",
      "Epoch 25, Loss: 2.1979095935821533\n",
      "Epoch 26, Loss: 2.3680214881896973\n",
      "Epoch 27, Loss: 2.318098545074463\n",
      "Epoch 28, Loss: 2.1977999210357666\n",
      "Epoch 29, Loss: 2.0965731143951416\n",
      "Epoch 30, Loss: 2.0385074615478516\n",
      "Epoch 31, Loss: 2.1763384342193604\n",
      "Epoch 32, Loss: 2.054877281188965\n",
      "Epoch 33, Loss: 2.043504238128662\n",
      "Epoch 34, Loss: 2.1868748664855957\n",
      "Epoch 35, Loss: 2.058274269104004\n",
      "Epoch 36, Loss: 2.006093978881836\n",
      "Epoch 37, Loss: 2.02243709564209\n",
      "Epoch 38, Loss: 2.039576292037964\n",
      "Epoch 39, Loss: 2.110917329788208\n",
      "Epoch 40, Loss: 2.0330758094787598\n",
      "Epoch 41, Loss: 2.0599963665008545\n",
      "Epoch 42, Loss: 1.8922468423843384\n",
      "Epoch 43, Loss: 1.9727908372879028\n",
      "Epoch 44, Loss: 1.9810501337051392\n",
      "Epoch 45, Loss: 1.9757581949234009\n",
      "Epoch 46, Loss: 1.985605239868164\n",
      "Epoch 47, Loss: 1.9762153625488281\n",
      "Epoch 48, Loss: 1.9538732767105103\n",
      "Epoch 49, Loss: 1.9004502296447754\n",
      "Epoch 50, Loss: 2.012712001800537\n",
      "Validation Accuracy: 0.1614\n",
      "Validation accuracy: 0.16137566137566137\n",
      "Training with lr=0.0005, hidden_sizes=[64, 128, 32], batch_size=16\n",
      "Epoch 1, Loss: 10.106475830078125\n",
      "Epoch 2, Loss: 5.9019927978515625\n",
      "Epoch 3, Loss: 1.6234211921691895\n",
      "Epoch 4, Loss: 1.9235628843307495\n",
      "Epoch 5, Loss: 2.5221505165100098\n",
      "Epoch 6, Loss: 2.519963026046753\n",
      "Epoch 7, Loss: 1.912235975265503\n",
      "Epoch 8, Loss: 1.9086947441101074\n",
      "Epoch 9, Loss: 1.9238642454147339\n",
      "Epoch 10, Loss: 2.136531352996826\n",
      "Epoch 11, Loss: 1.897821068763733\n",
      "Epoch 12, Loss: 1.9464740753173828\n",
      "Epoch 13, Loss: 1.831514835357666\n",
      "Epoch 14, Loss: 1.9247370958328247\n",
      "Epoch 15, Loss: 1.9406299591064453\n",
      "Epoch 16, Loss: 1.9032161235809326\n",
      "Epoch 17, Loss: 1.8815230131149292\n",
      "Epoch 18, Loss: 1.9761582612991333\n",
      "Epoch 19, Loss: 1.8281784057617188\n",
      "Epoch 20, Loss: 1.9334954023361206\n",
      "Epoch 21, Loss: 2.0622589588165283\n",
      "Epoch 22, Loss: 1.950650691986084\n",
      "Epoch 23, Loss: 1.8725645542144775\n",
      "Epoch 24, Loss: 1.8924168348312378\n",
      "Epoch 25, Loss: 1.8482649326324463\n",
      "Epoch 26, Loss: 1.9057796001434326\n",
      "Epoch 27, Loss: 1.9421952962875366\n",
      "Epoch 28, Loss: 1.8171080350875854\n",
      "Epoch 29, Loss: 1.7921055555343628\n",
      "Epoch 30, Loss: 1.8359464406967163\n",
      "Epoch 31, Loss: 1.801054835319519\n",
      "Epoch 32, Loss: 1.8320773839950562\n",
      "Epoch 33, Loss: 1.7335962057113647\n",
      "Epoch 34, Loss: 1.9150408506393433\n",
      "Epoch 35, Loss: 1.8334654569625854\n",
      "Epoch 36, Loss: 1.8259221315383911\n",
      "Epoch 37, Loss: 1.993759036064148\n",
      "Epoch 38, Loss: 1.8235650062561035\n",
      "Epoch 39, Loss: 1.9222424030303955\n",
      "Epoch 40, Loss: 1.9225518703460693\n",
      "Epoch 41, Loss: 1.8122475147247314\n",
      "Epoch 42, Loss: 1.8818668127059937\n",
      "Epoch 43, Loss: 1.9145023822784424\n",
      "Epoch 44, Loss: 1.8421649932861328\n",
      "Epoch 45, Loss: 1.7735040187835693\n",
      "Epoch 46, Loss: 1.8256791830062866\n",
      "Epoch 47, Loss: 1.9330151081085205\n",
      "Epoch 48, Loss: 1.77864670753479\n",
      "Epoch 49, Loss: 1.995049238204956\n",
      "Epoch 50, Loss: 1.9319673776626587\n",
      "Validation Accuracy: 0.1587\n",
      "Validation accuracy: 0.15873015873015872\n",
      "Training with lr=0.0005, hidden_sizes=[64, 128, 32], batch_size=32\n",
      "Epoch 1, Loss: 14.579564094543457\n",
      "Epoch 2, Loss: 12.65207290649414\n",
      "Epoch 3, Loss: 7.379251480102539\n",
      "Epoch 4, Loss: 2.504190683364868\n",
      "Epoch 5, Loss: 2.559990406036377\n",
      "Epoch 6, Loss: 3.5279743671417236\n",
      "Epoch 7, Loss: 2.5205376148223877\n",
      "Epoch 8, Loss: 1.8225347995758057\n",
      "Epoch 9, Loss: 2.2582192420959473\n",
      "Epoch 10, Loss: 1.9987355470657349\n",
      "Epoch 11, Loss: 2.429546594619751\n",
      "Epoch 12, Loss: 1.8659580945968628\n",
      "Epoch 13, Loss: 2.033073902130127\n",
      "Epoch 14, Loss: 1.8778493404388428\n",
      "Epoch 15, Loss: 2.2820985317230225\n",
      "Epoch 16, Loss: 1.8786661624908447\n",
      "Epoch 17, Loss: 2.0861876010894775\n",
      "Epoch 18, Loss: 2.265918493270874\n",
      "Epoch 19, Loss: 1.9850794076919556\n",
      "Epoch 20, Loss: 1.881524920463562\n",
      "Epoch 21, Loss: 1.898094892501831\n",
      "Epoch 22, Loss: 1.9101585149765015\n",
      "Epoch 23, Loss: 1.972994089126587\n",
      "Epoch 24, Loss: 1.990238904953003\n",
      "Epoch 25, Loss: 1.9292091131210327\n",
      "Epoch 26, Loss: 1.8499755859375\n",
      "Epoch 27, Loss: 1.9257076978683472\n",
      "Epoch 28, Loss: 2.1748270988464355\n",
      "Epoch 29, Loss: 1.9283379316329956\n",
      "Epoch 30, Loss: 1.7705844640731812\n",
      "Epoch 31, Loss: 1.898287296295166\n",
      "Epoch 32, Loss: 1.975875735282898\n",
      "Epoch 33, Loss: 1.8533949851989746\n",
      "Epoch 34, Loss: 1.8908525705337524\n",
      "Epoch 35, Loss: 1.8782671689987183\n",
      "Epoch 36, Loss: 1.954067349433899\n",
      "Epoch 37, Loss: 2.005063056945801\n",
      "Epoch 38, Loss: 1.8080980777740479\n",
      "Epoch 39, Loss: 2.002568244934082\n",
      "Epoch 40, Loss: 1.8684614896774292\n",
      "Epoch 41, Loss: 1.832203984260559\n",
      "Epoch 42, Loss: 1.8181078433990479\n",
      "Epoch 43, Loss: 2.259910821914673\n",
      "Epoch 44, Loss: 1.8500087261199951\n",
      "Epoch 45, Loss: 1.8366186618804932\n",
      "Epoch 46, Loss: 1.8120373487472534\n",
      "Epoch 47, Loss: 1.9508445262908936\n",
      "Epoch 48, Loss: 1.9604171514511108\n",
      "Epoch 49, Loss: 2.042188882827759\n",
      "Epoch 50, Loss: 1.8187439441680908\n",
      "Validation Accuracy: 0.1720\n",
      "Validation accuracy: 0.17195767195767195\n",
      "Training with lr=0.0005, hidden_sizes=[64, 128, 32], batch_size=64\n",
      "Epoch 1, Loss: 27.68736457824707\n",
      "Epoch 2, Loss: 12.870491027832031\n",
      "Epoch 3, Loss: 9.966840744018555\n",
      "Epoch 4, Loss: 5.502107620239258\n",
      "Epoch 5, Loss: 3.6126530170440674\n",
      "Epoch 6, Loss: 4.249006271362305\n",
      "Epoch 7, Loss: 3.467205286026001\n",
      "Epoch 8, Loss: 3.8982694149017334\n",
      "Epoch 9, Loss: 2.8269574642181396\n",
      "Epoch 10, Loss: 2.1332924365997314\n",
      "Epoch 11, Loss: 2.892791748046875\n",
      "Epoch 12, Loss: 2.516871929168701\n",
      "Epoch 13, Loss: 2.223600149154663\n",
      "Epoch 14, Loss: 2.335524559020996\n",
      "Epoch 15, Loss: 2.138521909713745\n",
      "Epoch 16, Loss: 2.1890439987182617\n",
      "Epoch 17, Loss: 1.9068150520324707\n",
      "Epoch 18, Loss: 2.055636167526245\n",
      "Epoch 19, Loss: 1.8914309740066528\n",
      "Epoch 20, Loss: 2.1279189586639404\n",
      "Epoch 21, Loss: 1.9583512544631958\n",
      "Epoch 22, Loss: 1.8813332319259644\n",
      "Epoch 23, Loss: 2.0920770168304443\n",
      "Epoch 24, Loss: 1.999245524406433\n",
      "Epoch 25, Loss: 1.872047781944275\n",
      "Epoch 26, Loss: 1.901845932006836\n",
      "Epoch 27, Loss: 1.9315438270568848\n",
      "Epoch 28, Loss: 1.8999844789505005\n",
      "Epoch 29, Loss: 1.8645944595336914\n",
      "Epoch 30, Loss: 2.0174553394317627\n",
      "Epoch 31, Loss: 1.9875839948654175\n",
      "Epoch 32, Loss: 1.9141159057617188\n",
      "Epoch 33, Loss: 1.91537344455719\n",
      "Epoch 34, Loss: 1.9131169319152832\n",
      "Epoch 35, Loss: 1.9009710550308228\n",
      "Epoch 36, Loss: 1.9324543476104736\n",
      "Epoch 37, Loss: 1.8877437114715576\n",
      "Epoch 38, Loss: 1.8507901430130005\n",
      "Epoch 39, Loss: 1.8662158250808716\n",
      "Epoch 40, Loss: 1.8838059902191162\n",
      "Epoch 41, Loss: 2.284059524536133\n",
      "Epoch 42, Loss: 1.8717920780181885\n",
      "Epoch 43, Loss: 1.8836238384246826\n",
      "Epoch 44, Loss: 1.8786917924880981\n",
      "Epoch 45, Loss: 2.00783371925354\n",
      "Epoch 46, Loss: 1.879513144493103\n",
      "Epoch 47, Loss: 1.925723671913147\n",
      "Epoch 48, Loss: 1.9007511138916016\n",
      "Epoch 49, Loss: 1.920113205909729\n",
      "Epoch 50, Loss: 1.9338041543960571\n",
      "Validation Accuracy: 0.1720\n",
      "Validation accuracy: 0.17195767195767195\n",
      "Training with lr=0.0005, hidden_sizes=[64, 128, 32], batch_size=128\n",
      "Epoch 1, Loss: 21.647605895996094\n",
      "Epoch 2, Loss: 17.859943389892578\n",
      "Epoch 3, Loss: 10.546092987060547\n",
      "Epoch 4, Loss: 7.964545249938965\n",
      "Epoch 5, Loss: 5.848151683807373\n",
      "Epoch 6, Loss: 5.361310005187988\n",
      "Epoch 7, Loss: 4.132812023162842\n",
      "Epoch 8, Loss: 4.502877712249756\n",
      "Epoch 9, Loss: 2.987008810043335\n",
      "Epoch 10, Loss: 2.927600383758545\n",
      "Epoch 11, Loss: 2.4247677326202393\n",
      "Epoch 12, Loss: 2.5919911861419678\n",
      "Epoch 13, Loss: 2.1404037475585938\n",
      "Epoch 14, Loss: 2.5829248428344727\n",
      "Epoch 15, Loss: 2.2115976810455322\n",
      "Epoch 16, Loss: 2.277719497680664\n",
      "Epoch 17, Loss: 2.073002815246582\n",
      "Epoch 18, Loss: 2.1371779441833496\n",
      "Epoch 19, Loss: 2.0197513103485107\n",
      "Epoch 20, Loss: 2.264627456665039\n",
      "Epoch 21, Loss: 2.0682947635650635\n",
      "Epoch 22, Loss: 2.154247760772705\n",
      "Epoch 23, Loss: 1.9212584495544434\n",
      "Epoch 24, Loss: 1.9438449144363403\n",
      "Epoch 25, Loss: 1.9364738464355469\n",
      "Epoch 26, Loss: 2.1393606662750244\n",
      "Epoch 27, Loss: 2.1836254596710205\n",
      "Epoch 28, Loss: 2.0759644508361816\n",
      "Epoch 29, Loss: 2.122208833694458\n",
      "Epoch 30, Loss: 2.3099172115325928\n",
      "Epoch 31, Loss: 2.122769594192505\n",
      "Epoch 32, Loss: 1.9213401079177856\n",
      "Epoch 33, Loss: 2.013131856918335\n",
      "Epoch 34, Loss: 1.9119822978973389\n",
      "Epoch 35, Loss: 1.967776894569397\n",
      "Epoch 36, Loss: 1.9794825315475464\n",
      "Epoch 37, Loss: 2.120307445526123\n",
      "Epoch 38, Loss: 1.9510560035705566\n",
      "Epoch 39, Loss: 1.9213935136795044\n",
      "Epoch 40, Loss: 1.8945587873458862\n",
      "Epoch 41, Loss: 1.9551676511764526\n",
      "Epoch 42, Loss: 2.0401952266693115\n",
      "Epoch 43, Loss: 1.9545416831970215\n",
      "Epoch 44, Loss: 1.9177836179733276\n",
      "Epoch 45, Loss: 1.99064040184021\n",
      "Epoch 46, Loss: 1.9030848741531372\n",
      "Epoch 47, Loss: 1.8966017961502075\n",
      "Epoch 48, Loss: 1.940936803817749\n",
      "Epoch 49, Loss: 1.9005937576293945\n",
      "Epoch 50, Loss: 1.895613670349121\n",
      "Validation Accuracy: 0.1825\n",
      "Validation accuracy: 0.18253968253968253\n",
      "Training with lr=0.0001, hidden_sizes=[128, 64], batch_size=16\n",
      "Epoch 1, Loss: 35.165550231933594\n",
      "Epoch 2, Loss: 37.17408752441406\n",
      "Epoch 3, Loss: 44.579647064208984\n",
      "Epoch 4, Loss: 40.24802780151367\n",
      "Epoch 5, Loss: 22.30321502685547\n",
      "Epoch 6, Loss: 17.313610076904297\n",
      "Epoch 7, Loss: 19.44659996032715\n",
      "Epoch 8, Loss: 19.761564254760742\n",
      "Epoch 9, Loss: 24.67854118347168\n",
      "Epoch 10, Loss: 9.04005241394043\n",
      "Epoch 11, Loss: 18.941530227661133\n",
      "Epoch 12, Loss: 15.742376327514648\n",
      "Epoch 13, Loss: 14.863429069519043\n",
      "Epoch 14, Loss: 15.063633918762207\n",
      "Epoch 15, Loss: 4.997885227203369\n",
      "Epoch 16, Loss: 5.826699733734131\n",
      "Epoch 17, Loss: 5.165705680847168\n",
      "Epoch 18, Loss: 3.5921218395233154\n",
      "Epoch 19, Loss: 10.086432456970215\n",
      "Epoch 20, Loss: 7.490248680114746\n",
      "Epoch 21, Loss: 4.392144203186035\n",
      "Epoch 22, Loss: 8.689024925231934\n",
      "Epoch 23, Loss: 3.4554340839385986\n",
      "Epoch 24, Loss: 4.6208062171936035\n",
      "Epoch 25, Loss: 2.707690715789795\n",
      "Epoch 26, Loss: 4.734042167663574\n",
      "Epoch 27, Loss: 4.128121852874756\n",
      "Epoch 28, Loss: 2.1878347396850586\n",
      "Epoch 29, Loss: 2.6060266494750977\n",
      "Epoch 30, Loss: 4.155546188354492\n",
      "Epoch 31, Loss: 3.3878402709960938\n",
      "Epoch 32, Loss: 3.35819149017334\n",
      "Epoch 33, Loss: 3.2335562705993652\n",
      "Epoch 34, Loss: 2.3817594051361084\n",
      "Epoch 35, Loss: 2.6465749740600586\n",
      "Epoch 36, Loss: 1.890342116355896\n",
      "Epoch 37, Loss: 1.7329105138778687\n",
      "Epoch 38, Loss: 2.0701370239257812\n",
      "Epoch 39, Loss: 2.485790491104126\n",
      "Epoch 40, Loss: 2.838803291320801\n",
      "Epoch 41, Loss: 2.009403705596924\n",
      "Epoch 42, Loss: 2.1944050788879395\n",
      "Epoch 43, Loss: 2.5027287006378174\n",
      "Epoch 44, Loss: 3.166883707046509\n",
      "Epoch 45, Loss: 1.9494394063949585\n",
      "Epoch 46, Loss: 1.7996166944503784\n",
      "Epoch 47, Loss: 1.9623018503189087\n",
      "Epoch 48, Loss: 2.0751986503601074\n",
      "Epoch 49, Loss: 1.9518234729766846\n",
      "Epoch 50, Loss: 1.7909507751464844\n",
      "Validation Accuracy: 0.2460\n",
      "Validation accuracy: 0.24603174603174602\n",
      "Training with lr=0.0001, hidden_sizes=[128, 64], batch_size=32\n",
      "Epoch 1, Loss: 40.56951904296875\n",
      "Epoch 2, Loss: 45.77477264404297\n",
      "Epoch 3, Loss: 35.67070007324219\n",
      "Epoch 4, Loss: 45.67321014404297\n",
      "Epoch 5, Loss: 27.691722869873047\n",
      "Epoch 6, Loss: 48.91966247558594\n",
      "Epoch 7, Loss: 28.62061309814453\n",
      "Epoch 8, Loss: 31.39674949645996\n",
      "Epoch 9, Loss: 26.392566680908203\n",
      "Epoch 10, Loss: 26.831249237060547\n",
      "Epoch 11, Loss: 23.888660430908203\n",
      "Epoch 12, Loss: 20.430179595947266\n",
      "Epoch 13, Loss: 16.55710220336914\n",
      "Epoch 14, Loss: 18.635066986083984\n",
      "Epoch 15, Loss: 16.559471130371094\n",
      "Epoch 16, Loss: 10.989120483398438\n",
      "Epoch 17, Loss: 15.844864845275879\n",
      "Epoch 18, Loss: 15.570143699645996\n",
      "Epoch 19, Loss: 12.192879676818848\n",
      "Epoch 20, Loss: 7.663514137268066\n",
      "Epoch 21, Loss: 5.816760063171387\n",
      "Epoch 22, Loss: 12.09599494934082\n",
      "Epoch 23, Loss: 6.943412780761719\n",
      "Epoch 24, Loss: 11.062808990478516\n",
      "Epoch 25, Loss: 10.601945877075195\n",
      "Epoch 26, Loss: 4.14710807800293\n",
      "Epoch 27, Loss: 6.444684028625488\n",
      "Epoch 28, Loss: 6.954183578491211\n",
      "Epoch 29, Loss: 13.235953330993652\n",
      "Epoch 30, Loss: 3.5268049240112305\n",
      "Epoch 31, Loss: 3.9996626377105713\n",
      "Epoch 32, Loss: 4.168583393096924\n",
      "Epoch 33, Loss: 4.12040376663208\n",
      "Epoch 34, Loss: 5.441986083984375\n",
      "Epoch 35, Loss: 4.540464878082275\n",
      "Epoch 36, Loss: 2.66599440574646\n",
      "Epoch 37, Loss: 2.851043462753296\n",
      "Epoch 38, Loss: 5.9233269691467285\n",
      "Epoch 39, Loss: 4.071064472198486\n",
      "Epoch 40, Loss: 1.691625714302063\n",
      "Epoch 41, Loss: 2.6531758308410645\n",
      "Epoch 42, Loss: 3.856959581375122\n",
      "Epoch 43, Loss: 5.59564208984375\n",
      "Epoch 44, Loss: 2.0763556957244873\n",
      "Epoch 45, Loss: 2.620098352432251\n",
      "Epoch 46, Loss: 2.597888231277466\n",
      "Epoch 47, Loss: 2.8986823558807373\n",
      "Epoch 48, Loss: 4.232377529144287\n",
      "Epoch 49, Loss: 4.292509078979492\n",
      "Epoch 50, Loss: 3.9390485286712646\n",
      "Validation Accuracy: 0.1772\n",
      "Validation accuracy: 0.17724867724867724\n",
      "Training with lr=0.0001, hidden_sizes=[128, 64], batch_size=64\n",
      "Epoch 1, Loss: 45.80642318725586\n",
      "Epoch 2, Loss: 39.9849853515625\n",
      "Epoch 3, Loss: 46.06309127807617\n",
      "Epoch 4, Loss: 38.49052429199219\n",
      "Epoch 5, Loss: 49.450313568115234\n",
      "Epoch 6, Loss: 44.42760467529297\n",
      "Epoch 7, Loss: 35.29442596435547\n",
      "Epoch 8, Loss: 39.116703033447266\n",
      "Epoch 9, Loss: 33.269203186035156\n",
      "Epoch 10, Loss: 38.87051773071289\n",
      "Epoch 11, Loss: 33.01662826538086\n",
      "Epoch 12, Loss: 34.937095642089844\n",
      "Epoch 13, Loss: 29.18059730529785\n",
      "Epoch 14, Loss: 28.09623908996582\n",
      "Epoch 15, Loss: 26.84977912902832\n",
      "Epoch 16, Loss: 25.10146713256836\n",
      "Epoch 17, Loss: 20.618240356445312\n",
      "Epoch 18, Loss: 23.795196533203125\n",
      "Epoch 19, Loss: 15.689111709594727\n",
      "Epoch 20, Loss: 23.738086700439453\n",
      "Epoch 21, Loss: 22.326087951660156\n",
      "Epoch 22, Loss: 20.321870803833008\n",
      "Epoch 23, Loss: 15.258920669555664\n",
      "Epoch 24, Loss: 13.654447555541992\n",
      "Epoch 25, Loss: 13.89044189453125\n",
      "Epoch 26, Loss: 16.033466339111328\n",
      "Epoch 27, Loss: 19.246959686279297\n",
      "Epoch 28, Loss: 10.98737907409668\n",
      "Epoch 29, Loss: 16.38054847717285\n",
      "Epoch 30, Loss: 15.084516525268555\n",
      "Epoch 31, Loss: 9.325897216796875\n",
      "Epoch 32, Loss: 11.837599754333496\n",
      "Epoch 33, Loss: 11.282405853271484\n",
      "Epoch 34, Loss: 11.558357238769531\n",
      "Epoch 35, Loss: 12.043726921081543\n",
      "Epoch 36, Loss: 10.537185668945312\n",
      "Epoch 37, Loss: 7.516045570373535\n",
      "Epoch 38, Loss: 7.478872299194336\n",
      "Epoch 39, Loss: 10.66577434539795\n",
      "Epoch 40, Loss: 10.24052619934082\n",
      "Epoch 41, Loss: 6.130134582519531\n",
      "Epoch 42, Loss: 7.703842639923096\n",
      "Epoch 43, Loss: 8.98826789855957\n",
      "Epoch 44, Loss: 7.455909252166748\n",
      "Epoch 45, Loss: 5.223374843597412\n",
      "Epoch 46, Loss: 4.997720241546631\n",
      "Epoch 47, Loss: 6.724701404571533\n",
      "Epoch 48, Loss: 6.489534854888916\n",
      "Epoch 49, Loss: 3.8929154872894287\n",
      "Epoch 50, Loss: 4.497660160064697\n",
      "Validation Accuracy: 0.2196\n",
      "Validation accuracy: 0.21957671957671956\n",
      "Training with lr=0.0001, hidden_sizes=[128, 64], batch_size=128\n",
      "Epoch 1, Loss: 63.70729446411133\n",
      "Epoch 2, Loss: 46.22885513305664\n",
      "Epoch 3, Loss: 55.29454803466797\n",
      "Epoch 4, Loss: 42.80075454711914\n",
      "Epoch 5, Loss: 40.47311782836914\n",
      "Epoch 6, Loss: 44.575347900390625\n",
      "Epoch 7, Loss: 39.21748733520508\n",
      "Epoch 8, Loss: 38.82964324951172\n",
      "Epoch 9, Loss: 43.750648498535156\n",
      "Epoch 10, Loss: 35.449039459228516\n",
      "Epoch 11, Loss: 33.303829193115234\n",
      "Epoch 12, Loss: 39.829078674316406\n",
      "Epoch 13, Loss: 32.52592849731445\n",
      "Epoch 14, Loss: 30.225500106811523\n",
      "Epoch 15, Loss: 30.684171676635742\n",
      "Epoch 16, Loss: 27.055978775024414\n",
      "Epoch 17, Loss: 30.49161720275879\n",
      "Epoch 18, Loss: 28.641704559326172\n",
      "Epoch 19, Loss: 26.87169075012207\n",
      "Epoch 20, Loss: 28.53484535217285\n",
      "Epoch 21, Loss: 23.859111785888672\n",
      "Epoch 22, Loss: 22.79411506652832\n",
      "Epoch 23, Loss: 25.699237823486328\n",
      "Epoch 24, Loss: 18.663494110107422\n",
      "Epoch 25, Loss: 17.110910415649414\n",
      "Epoch 26, Loss: 21.134681701660156\n",
      "Epoch 27, Loss: 20.72104835510254\n",
      "Epoch 28, Loss: 18.0039005279541\n",
      "Epoch 29, Loss: 18.52518081665039\n",
      "Epoch 30, Loss: 18.503313064575195\n",
      "Epoch 31, Loss: 18.11581039428711\n",
      "Epoch 32, Loss: 19.789993286132812\n",
      "Epoch 33, Loss: 18.008819580078125\n",
      "Epoch 34, Loss: 18.051847457885742\n",
      "Epoch 35, Loss: 15.372920036315918\n",
      "Epoch 36, Loss: 14.446208000183105\n",
      "Epoch 37, Loss: 14.776975631713867\n",
      "Epoch 38, Loss: 15.814286231994629\n",
      "Epoch 39, Loss: 12.469417572021484\n",
      "Epoch 40, Loss: 13.196354866027832\n",
      "Epoch 41, Loss: 11.119756698608398\n",
      "Epoch 42, Loss: 11.575125694274902\n",
      "Epoch 43, Loss: 11.898153305053711\n",
      "Epoch 44, Loss: 11.641270637512207\n",
      "Epoch 45, Loss: 11.237996101379395\n",
      "Epoch 46, Loss: 10.512737274169922\n",
      "Epoch 47, Loss: 10.236236572265625\n",
      "Epoch 48, Loss: 9.56099796295166\n",
      "Epoch 49, Loss: 9.89467716217041\n",
      "Epoch 50, Loss: 10.254974365234375\n",
      "Validation Accuracy: 0.2593\n",
      "Validation accuracy: 0.25925925925925924\n",
      "Training with lr=0.0001, hidden_sizes=[128, 64, 32], batch_size=16\n",
      "Epoch 1, Loss: 21.141719818115234\n",
      "Epoch 2, Loss: 22.51576042175293\n",
      "Epoch 3, Loss: 12.15538501739502\n",
      "Epoch 4, Loss: 20.22740936279297\n",
      "Epoch 5, Loss: 9.442353248596191\n",
      "Epoch 6, Loss: 6.475261211395264\n",
      "Epoch 7, Loss: 8.754892349243164\n",
      "Epoch 8, Loss: 8.429137229919434\n",
      "Epoch 9, Loss: 10.554563522338867\n",
      "Epoch 10, Loss: 6.759576797485352\n",
      "Epoch 11, Loss: 5.709542751312256\n",
      "Epoch 12, Loss: 6.952652931213379\n",
      "Epoch 13, Loss: 5.929048538208008\n",
      "Epoch 14, Loss: 5.371214866638184\n",
      "Epoch 15, Loss: 6.571354389190674\n",
      "Epoch 16, Loss: 7.096962928771973\n",
      "Epoch 17, Loss: 5.99993896484375\n",
      "Epoch 18, Loss: 6.055063724517822\n",
      "Epoch 19, Loss: 3.414198637008667\n",
      "Epoch 20, Loss: 4.689591884613037\n",
      "Epoch 21, Loss: 2.8083536624908447\n",
      "Epoch 22, Loss: 3.026710271835327\n",
      "Epoch 23, Loss: 5.250527381896973\n",
      "Epoch 24, Loss: 1.8316669464111328\n",
      "Epoch 25, Loss: 3.8774068355560303\n",
      "Epoch 26, Loss: 3.01374888420105\n",
      "Epoch 27, Loss: 2.4373536109924316\n",
      "Epoch 28, Loss: 2.305691957473755\n",
      "Epoch 29, Loss: 2.604827642440796\n",
      "Epoch 30, Loss: 2.097137451171875\n",
      "Epoch 31, Loss: 2.0779407024383545\n",
      "Epoch 32, Loss: 3.288649797439575\n",
      "Epoch 33, Loss: 3.146174192428589\n",
      "Epoch 34, Loss: 2.978752374649048\n",
      "Epoch 35, Loss: 1.7425214052200317\n",
      "Epoch 36, Loss: 1.9718424081802368\n",
      "Epoch 37, Loss: 2.3880727291107178\n",
      "Epoch 38, Loss: 2.73858380317688\n",
      "Epoch 39, Loss: 2.8123726844787598\n",
      "Epoch 40, Loss: 1.9157041311264038\n",
      "Epoch 41, Loss: 2.748300313949585\n",
      "Epoch 42, Loss: 1.872874140739441\n",
      "Epoch 43, Loss: 1.7967292070388794\n",
      "Epoch 44, Loss: 2.3585550785064697\n",
      "Epoch 45, Loss: 2.924029588699341\n",
      "Epoch 46, Loss: 2.3076748847961426\n",
      "Epoch 47, Loss: 2.3207857608795166\n",
      "Epoch 48, Loss: 2.258796453475952\n",
      "Epoch 49, Loss: 2.7749111652374268\n",
      "Epoch 50, Loss: 1.8978534936904907\n",
      "Validation Accuracy: 0.1720\n",
      "Validation accuracy: 0.17195767195767195\n",
      "Training with lr=0.0001, hidden_sizes=[128, 64, 32], batch_size=32\n",
      "Epoch 1, Loss: 29.065526962280273\n",
      "Epoch 2, Loss: 21.72357177734375\n",
      "Epoch 3, Loss: 9.922857284545898\n",
      "Epoch 4, Loss: 13.99452018737793\n",
      "Epoch 5, Loss: 13.226261138916016\n",
      "Epoch 6, Loss: 9.229339599609375\n",
      "Epoch 7, Loss: 17.650049209594727\n",
      "Epoch 8, Loss: 11.015009880065918\n",
      "Epoch 9, Loss: 6.750575542449951\n",
      "Epoch 10, Loss: 8.944968223571777\n",
      "Epoch 11, Loss: 8.22487735748291\n",
      "Epoch 12, Loss: 7.012444019317627\n",
      "Epoch 13, Loss: 8.70644474029541\n",
      "Epoch 14, Loss: 11.37328052520752\n",
      "Epoch 15, Loss: 4.9168267250061035\n",
      "Epoch 16, Loss: 5.773060321807861\n",
      "Epoch 17, Loss: 6.3559160232543945\n",
      "Epoch 18, Loss: 6.455278396606445\n",
      "Epoch 19, Loss: 6.671050071716309\n",
      "Epoch 20, Loss: 6.293445110321045\n",
      "Epoch 21, Loss: 3.6741857528686523\n",
      "Epoch 22, Loss: 2.0010170936584473\n",
      "Epoch 23, Loss: 6.178635597229004\n",
      "Epoch 24, Loss: 5.083809852600098\n",
      "Epoch 25, Loss: 3.0269927978515625\n",
      "Epoch 26, Loss: 1.9881938695907593\n",
      "Epoch 27, Loss: 2.21406888961792\n",
      "Epoch 28, Loss: 1.9877480268478394\n",
      "Epoch 29, Loss: 4.923134803771973\n",
      "Epoch 30, Loss: 4.726047039031982\n",
      "Epoch 31, Loss: 2.906485080718994\n",
      "Epoch 32, Loss: 2.638601779937744\n",
      "Epoch 33, Loss: 2.414271593093872\n",
      "Epoch 34, Loss: 2.5896010398864746\n",
      "Epoch 35, Loss: 2.075230836868286\n",
      "Epoch 36, Loss: 2.2822375297546387\n",
      "Epoch 37, Loss: 2.8080804347991943\n",
      "Epoch 38, Loss: 4.484202861785889\n",
      "Epoch 39, Loss: 2.3629629611968994\n",
      "Epoch 40, Loss: 3.301954746246338\n",
      "Epoch 41, Loss: 3.4938747882843018\n",
      "Epoch 42, Loss: 2.7917850017547607\n",
      "Epoch 43, Loss: 2.134793996810913\n",
      "Epoch 44, Loss: 2.74873685836792\n",
      "Epoch 45, Loss: 2.309439182281494\n",
      "Epoch 46, Loss: 2.315662145614624\n",
      "Epoch 47, Loss: 2.7689871788024902\n",
      "Epoch 48, Loss: 2.1335527896881104\n",
      "Epoch 49, Loss: 2.6497879028320312\n",
      "Epoch 50, Loss: 1.9999819993972778\n",
      "Validation Accuracy: 0.1825\n",
      "Validation accuracy: 0.18253968253968253\n",
      "Training with lr=0.0001, hidden_sizes=[128, 64, 32], batch_size=64\n",
      "Epoch 1, Loss: 29.24049949645996\n",
      "Epoch 2, Loss: 19.163318634033203\n",
      "Epoch 3, Loss: 16.712604522705078\n",
      "Epoch 4, Loss: 18.641162872314453\n",
      "Epoch 5, Loss: 17.903057098388672\n",
      "Epoch 6, Loss: 16.238706588745117\n",
      "Epoch 7, Loss: 17.655370712280273\n",
      "Epoch 8, Loss: 12.184968948364258\n",
      "Epoch 9, Loss: 15.350261688232422\n",
      "Epoch 10, Loss: 12.894570350646973\n",
      "Epoch 11, Loss: 11.133260726928711\n",
      "Epoch 12, Loss: 8.067133903503418\n",
      "Epoch 13, Loss: 9.616012573242188\n",
      "Epoch 14, Loss: 8.920357704162598\n",
      "Epoch 15, Loss: 6.528512477874756\n",
      "Epoch 16, Loss: 9.029692649841309\n",
      "Epoch 17, Loss: 5.794459342956543\n",
      "Epoch 18, Loss: 8.269050598144531\n",
      "Epoch 19, Loss: 7.467644691467285\n",
      "Epoch 20, Loss: 5.682275772094727\n",
      "Epoch 21, Loss: 7.842483043670654\n",
      "Epoch 22, Loss: 7.737651348114014\n",
      "Epoch 23, Loss: 6.033962726593018\n",
      "Epoch 24, Loss: 6.667424201965332\n",
      "Epoch 25, Loss: 6.27932071685791\n",
      "Epoch 26, Loss: 5.490799903869629\n",
      "Epoch 27, Loss: 5.724956035614014\n",
      "Epoch 28, Loss: 5.457798004150391\n",
      "Epoch 29, Loss: 5.199400424957275\n",
      "Epoch 30, Loss: 4.09510612487793\n",
      "Epoch 31, Loss: 5.097919464111328\n",
      "Epoch 32, Loss: 4.595221996307373\n",
      "Epoch 33, Loss: 4.79121208190918\n",
      "Epoch 34, Loss: 4.527149200439453\n",
      "Epoch 35, Loss: 4.2206854820251465\n",
      "Epoch 36, Loss: 3.531662940979004\n",
      "Epoch 37, Loss: 4.814024448394775\n",
      "Epoch 38, Loss: 2.76774525642395\n",
      "Epoch 39, Loss: 3.876511812210083\n",
      "Epoch 40, Loss: 3.7686734199523926\n",
      "Epoch 41, Loss: 4.031350135803223\n",
      "Epoch 42, Loss: 3.14125657081604\n",
      "Epoch 43, Loss: 4.128240585327148\n",
      "Epoch 44, Loss: 3.540994167327881\n",
      "Epoch 45, Loss: 3.464968681335449\n",
      "Epoch 46, Loss: 2.742755889892578\n",
      "Epoch 47, Loss: 3.063974142074585\n",
      "Epoch 48, Loss: 2.9759469032287598\n",
      "Epoch 49, Loss: 3.04316782951355\n",
      "Epoch 50, Loss: 3.3163886070251465\n",
      "Validation Accuracy: 0.1587\n",
      "Validation accuracy: 0.15873015873015872\n",
      "Training with lr=0.0001, hidden_sizes=[128, 64, 32], batch_size=128\n",
      "Epoch 1, Loss: 30.247955322265625\n",
      "Epoch 2, Loss: 29.553802490234375\n",
      "Epoch 3, Loss: 27.635156631469727\n",
      "Epoch 4, Loss: 27.093175888061523\n",
      "Epoch 5, Loss: 25.413055419921875\n",
      "Epoch 6, Loss: 24.133886337280273\n",
      "Epoch 7, Loss: 22.606700897216797\n",
      "Epoch 8, Loss: 21.879987716674805\n",
      "Epoch 9, Loss: 19.495189666748047\n",
      "Epoch 10, Loss: 17.613210678100586\n",
      "Epoch 11, Loss: 17.912851333618164\n",
      "Epoch 12, Loss: 17.097698211669922\n",
      "Epoch 13, Loss: 14.093819618225098\n",
      "Epoch 14, Loss: 17.171323776245117\n",
      "Epoch 15, Loss: 13.657391548156738\n",
      "Epoch 16, Loss: 15.264142990112305\n",
      "Epoch 17, Loss: 13.356803894042969\n",
      "Epoch 18, Loss: 14.446561813354492\n",
      "Epoch 19, Loss: 10.320566177368164\n",
      "Epoch 20, Loss: 11.68598747253418\n",
      "Epoch 21, Loss: 10.677035331726074\n",
      "Epoch 22, Loss: 12.210782051086426\n",
      "Epoch 23, Loss: 10.324590682983398\n",
      "Epoch 24, Loss: 10.808145523071289\n",
      "Epoch 25, Loss: 10.916842460632324\n",
      "Epoch 26, Loss: 8.860664367675781\n",
      "Epoch 27, Loss: 8.661287307739258\n",
      "Epoch 28, Loss: 9.673892974853516\n",
      "Epoch 29, Loss: 7.6993842124938965\n",
      "Epoch 30, Loss: 8.995070457458496\n",
      "Epoch 31, Loss: 7.479326248168945\n",
      "Epoch 32, Loss: 9.75179672241211\n",
      "Epoch 33, Loss: 7.202808380126953\n",
      "Epoch 34, Loss: 6.3549957275390625\n",
      "Epoch 35, Loss: 8.404839515686035\n",
      "Epoch 36, Loss: 6.536357879638672\n",
      "Epoch 37, Loss: 8.632506370544434\n",
      "Epoch 38, Loss: 8.104199409484863\n",
      "Epoch 39, Loss: 6.61087703704834\n",
      "Epoch 40, Loss: 6.734866619110107\n",
      "Epoch 41, Loss: 6.104117393493652\n",
      "Epoch 42, Loss: 5.820208549499512\n",
      "Epoch 43, Loss: 5.441927433013916\n",
      "Epoch 44, Loss: 6.705283164978027\n",
      "Epoch 45, Loss: 5.7586541175842285\n",
      "Epoch 46, Loss: 6.863930702209473\n",
      "Epoch 47, Loss: 5.674484729766846\n",
      "Epoch 48, Loss: 5.1720662117004395\n",
      "Epoch 49, Loss: 3.94404935836792\n",
      "Epoch 50, Loss: 4.736992359161377\n",
      "Validation Accuracy: 0.2222\n",
      "Validation accuracy: 0.2222222222222222\n",
      "Training with lr=0.0001, hidden_sizes=[128, 64, 32, 16], batch_size=16\n",
      "Epoch 1, Loss: 15.989139556884766\n",
      "Epoch 2, Loss: 6.500210762023926\n",
      "Epoch 3, Loss: 6.542135238647461\n",
      "Epoch 4, Loss: 4.614944934844971\n",
      "Epoch 5, Loss: 7.582107067108154\n",
      "Epoch 6, Loss: 6.164026737213135\n",
      "Epoch 7, Loss: 6.269954204559326\n",
      "Epoch 8, Loss: 2.968122959136963\n",
      "Epoch 9, Loss: 4.682916164398193\n",
      "Epoch 10, Loss: 5.276735305786133\n",
      "Epoch 11, Loss: 4.052708625793457\n",
      "Epoch 12, Loss: 2.897740602493286\n",
      "Epoch 13, Loss: 2.3834450244903564\n",
      "Epoch 14, Loss: 2.5913898944854736\n",
      "Epoch 15, Loss: 2.885922431945801\n",
      "Epoch 16, Loss: 2.734903573989868\n",
      "Epoch 17, Loss: 2.6754167079925537\n",
      "Epoch 18, Loss: 2.960094451904297\n",
      "Epoch 19, Loss: 2.344200611114502\n",
      "Epoch 20, Loss: 2.0735161304473877\n",
      "Epoch 21, Loss: 3.0273008346557617\n",
      "Epoch 22, Loss: 1.8549288511276245\n",
      "Epoch 23, Loss: 2.980428457260132\n",
      "Epoch 24, Loss: 2.0839688777923584\n",
      "Epoch 25, Loss: 1.8328474760055542\n",
      "Epoch 26, Loss: 2.2701423168182373\n",
      "Epoch 27, Loss: 2.109079599380493\n",
      "Epoch 28, Loss: 1.969957947731018\n",
      "Epoch 29, Loss: 1.9841313362121582\n",
      "Epoch 30, Loss: 2.338710308074951\n",
      "Epoch 31, Loss: 2.4078164100646973\n",
      "Epoch 32, Loss: 2.0683088302612305\n",
      "Epoch 33, Loss: 2.138549327850342\n",
      "Epoch 34, Loss: 2.0152812004089355\n",
      "Epoch 35, Loss: 1.8026089668273926\n",
      "Epoch 36, Loss: 2.1892454624176025\n",
      "Epoch 37, Loss: 2.0473525524139404\n",
      "Epoch 38, Loss: 2.18324613571167\n",
      "Epoch 39, Loss: 2.1662237644195557\n",
      "Epoch 40, Loss: 2.2347123622894287\n",
      "Epoch 41, Loss: 2.075754404067993\n",
      "Epoch 42, Loss: 1.7934668064117432\n",
      "Epoch 43, Loss: 2.1907734870910645\n",
      "Epoch 44, Loss: 1.9198466539382935\n",
      "Epoch 45, Loss: 2.474409341812134\n",
      "Epoch 46, Loss: 2.0246877670288086\n",
      "Epoch 47, Loss: 1.9762438535690308\n",
      "Epoch 48, Loss: 2.189107656478882\n",
      "Epoch 49, Loss: 1.8705464601516724\n",
      "Epoch 50, Loss: 1.8020907640457153\n",
      "Validation Accuracy: 0.1825\n",
      "Validation accuracy: 0.18253968253968253\n",
      "Training with lr=0.0001, hidden_sizes=[128, 64, 32, 16], batch_size=32\n",
      "Epoch 1, Loss: 8.60782241821289\n",
      "Epoch 2, Loss: 8.891837120056152\n",
      "Epoch 3, Loss: 13.975557327270508\n",
      "Epoch 4, Loss: 3.973351240158081\n",
      "Epoch 5, Loss: 7.7296905517578125\n",
      "Epoch 6, Loss: 6.0004167556762695\n",
      "Epoch 7, Loss: 5.392180919647217\n",
      "Epoch 8, Loss: 3.759514570236206\n",
      "Epoch 9, Loss: 4.656186580657959\n",
      "Epoch 10, Loss: 4.540951728820801\n",
      "Epoch 11, Loss: 6.573049545288086\n",
      "Epoch 12, Loss: 2.7487473487854004\n",
      "Epoch 13, Loss: 4.0274152755737305\n",
      "Epoch 14, Loss: 2.6062815189361572\n",
      "Epoch 15, Loss: 3.772270917892456\n",
      "Epoch 16, Loss: 2.3664562702178955\n",
      "Epoch 17, Loss: 3.5569636821746826\n",
      "Epoch 18, Loss: 3.0626838207244873\n",
      "Epoch 19, Loss: 2.0383453369140625\n",
      "Epoch 20, Loss: 2.752293586730957\n",
      "Epoch 21, Loss: 2.8852479457855225\n",
      "Epoch 22, Loss: 2.059241533279419\n",
      "Epoch 23, Loss: 1.7754675149917603\n",
      "Epoch 24, Loss: 2.554837226867676\n",
      "Epoch 25, Loss: 2.468471050262451\n",
      "Epoch 26, Loss: 3.3481624126434326\n",
      "Epoch 27, Loss: 1.7555193901062012\n",
      "Epoch 28, Loss: 2.1402335166931152\n",
      "Epoch 29, Loss: 1.7317008972167969\n",
      "Epoch 30, Loss: 2.132288932800293\n",
      "Epoch 31, Loss: 2.10159969329834\n",
      "Epoch 32, Loss: 2.5042271614074707\n",
      "Epoch 33, Loss: 2.107042074203491\n",
      "Epoch 34, Loss: 2.5348687171936035\n",
      "Epoch 35, Loss: 1.890648365020752\n",
      "Epoch 36, Loss: 2.3148579597473145\n",
      "Epoch 37, Loss: 2.2742738723754883\n",
      "Epoch 38, Loss: 2.433377504348755\n",
      "Epoch 39, Loss: 1.9252088069915771\n",
      "Epoch 40, Loss: 2.182309865951538\n",
      "Epoch 41, Loss: 2.9768362045288086\n",
      "Epoch 42, Loss: 2.1957366466522217\n",
      "Epoch 43, Loss: 1.8992646932601929\n",
      "Epoch 44, Loss: 1.884514331817627\n",
      "Epoch 45, Loss: 2.1369409561157227\n",
      "Epoch 46, Loss: 2.1075470447540283\n",
      "Epoch 47, Loss: 2.122917890548706\n",
      "Epoch 48, Loss: 1.9686014652252197\n",
      "Epoch 49, Loss: 2.2047810554504395\n",
      "Epoch 50, Loss: 1.794583797454834\n",
      "Validation Accuracy: 0.1746\n",
      "Validation accuracy: 0.1746031746031746\n",
      "Training with lr=0.0001, hidden_sizes=[128, 64, 32, 16], batch_size=64\n",
      "Epoch 1, Loss: 15.864134788513184\n",
      "Epoch 2, Loss: 15.028668403625488\n",
      "Epoch 3, Loss: 11.380207061767578\n",
      "Epoch 4, Loss: 8.463276863098145\n",
      "Epoch 5, Loss: 8.927214622497559\n",
      "Epoch 6, Loss: 6.7308831214904785\n",
      "Epoch 7, Loss: 7.373622894287109\n",
      "Epoch 8, Loss: 5.586034774780273\n",
      "Epoch 9, Loss: 6.510542392730713\n",
      "Epoch 10, Loss: 5.042344093322754\n",
      "Epoch 11, Loss: 4.58119010925293\n",
      "Epoch 12, Loss: 5.761557579040527\n",
      "Epoch 13, Loss: 4.649663925170898\n",
      "Epoch 14, Loss: 4.814164638519287\n",
      "Epoch 15, Loss: 4.034965991973877\n",
      "Epoch 16, Loss: 4.794015407562256\n",
      "Epoch 17, Loss: 4.3852643966674805\n",
      "Epoch 18, Loss: 3.325648784637451\n",
      "Epoch 19, Loss: 3.661792516708374\n",
      "Epoch 20, Loss: 4.94985294342041\n",
      "Epoch 21, Loss: 3.756209135055542\n",
      "Epoch 22, Loss: 3.349914789199829\n",
      "Epoch 23, Loss: 3.7215065956115723\n",
      "Epoch 24, Loss: 2.9481360912323\n",
      "Epoch 25, Loss: 3.6975526809692383\n",
      "Epoch 26, Loss: 3.1014063358306885\n",
      "Epoch 27, Loss: 3.2904486656188965\n",
      "Epoch 28, Loss: 3.0767769813537598\n",
      "Epoch 29, Loss: 3.6336965560913086\n",
      "Epoch 30, Loss: 3.743560791015625\n",
      "Epoch 31, Loss: 2.846644401550293\n",
      "Epoch 32, Loss: 3.7156147956848145\n",
      "Epoch 33, Loss: 3.9127769470214844\n",
      "Epoch 34, Loss: 2.4832451343536377\n",
      "Epoch 35, Loss: 2.851149559020996\n",
      "Epoch 36, Loss: 3.718485116958618\n",
      "Epoch 37, Loss: 2.300835371017456\n",
      "Epoch 38, Loss: 3.050548791885376\n",
      "Epoch 39, Loss: 2.3721718788146973\n",
      "Epoch 40, Loss: 2.700849771499634\n",
      "Epoch 41, Loss: 2.3122718334198\n",
      "Epoch 42, Loss: 2.5009124279022217\n",
      "Epoch 43, Loss: 2.8985326290130615\n",
      "Epoch 44, Loss: 2.5698626041412354\n",
      "Epoch 45, Loss: 3.069613456726074\n",
      "Epoch 46, Loss: 3.3164825439453125\n",
      "Epoch 47, Loss: 2.3029329776763916\n",
      "Epoch 48, Loss: 2.63983154296875\n",
      "Epoch 49, Loss: 2.2757136821746826\n",
      "Epoch 50, Loss: 2.1152124404907227\n",
      "Validation Accuracy: 0.2169\n",
      "Validation accuracy: 0.21693121693121692\n",
      "Training with lr=0.0001, hidden_sizes=[128, 64, 32, 16], batch_size=128\n",
      "Epoch 1, Loss: 17.1597900390625\n",
      "Epoch 2, Loss: 13.155842781066895\n",
      "Epoch 3, Loss: 12.722954750061035\n",
      "Epoch 4, Loss: 12.05604362487793\n",
      "Epoch 5, Loss: 13.336762428283691\n",
      "Epoch 6, Loss: 11.577840805053711\n",
      "Epoch 7, Loss: 10.28177547454834\n",
      "Epoch 8, Loss: 8.517890930175781\n",
      "Epoch 9, Loss: 8.5681734085083\n",
      "Epoch 10, Loss: 8.830371856689453\n",
      "Epoch 11, Loss: 7.976770401000977\n",
      "Epoch 12, Loss: 8.149412155151367\n",
      "Epoch 13, Loss: 7.044042587280273\n",
      "Epoch 14, Loss: 8.161540031433105\n",
      "Epoch 15, Loss: 7.754693984985352\n",
      "Epoch 16, Loss: 6.789353847503662\n",
      "Epoch 17, Loss: 6.506288051605225\n",
      "Epoch 18, Loss: 5.8632917404174805\n",
      "Epoch 19, Loss: 5.166683673858643\n",
      "Epoch 20, Loss: 6.365067958831787\n",
      "Epoch 21, Loss: 6.231449604034424\n",
      "Epoch 22, Loss: 4.799172878265381\n",
      "Epoch 23, Loss: 4.916962623596191\n",
      "Epoch 24, Loss: 4.58535623550415\n",
      "Epoch 25, Loss: 4.966226577758789\n",
      "Epoch 26, Loss: 4.369550704956055\n",
      "Epoch 27, Loss: 5.396721363067627\n",
      "Epoch 28, Loss: 4.0334625244140625\n",
      "Epoch 29, Loss: 5.0065507888793945\n",
      "Epoch 30, Loss: 5.7945709228515625\n",
      "Epoch 31, Loss: 5.34031343460083\n",
      "Epoch 32, Loss: 4.555217742919922\n",
      "Epoch 33, Loss: 3.823127508163452\n",
      "Epoch 34, Loss: 3.235018014907837\n",
      "Epoch 35, Loss: 3.926389694213867\n",
      "Epoch 36, Loss: 3.305825710296631\n",
      "Epoch 37, Loss: 4.613302230834961\n",
      "Epoch 38, Loss: 3.2816576957702637\n",
      "Epoch 39, Loss: 3.8704845905303955\n",
      "Epoch 40, Loss: 4.1259870529174805\n",
      "Epoch 41, Loss: 4.17653226852417\n",
      "Epoch 42, Loss: 2.8338356018066406\n",
      "Epoch 43, Loss: 2.796114206314087\n",
      "Epoch 44, Loss: 2.810746908187866\n",
      "Epoch 45, Loss: 3.006065845489502\n",
      "Epoch 46, Loss: 4.068276405334473\n",
      "Epoch 47, Loss: 3.495222330093384\n",
      "Epoch 48, Loss: 3.0761349201202393\n",
      "Epoch 49, Loss: 2.970421075820923\n",
      "Epoch 50, Loss: 3.3728883266448975\n",
      "Validation Accuracy: 0.1772\n",
      "Validation accuracy: 0.17724867724867724\n",
      "Training with lr=0.0001, hidden_sizes=[64, 128, 32], batch_size=16\n",
      "Epoch 1, Loss: 13.893988609313965\n",
      "Epoch 2, Loss: 23.14085578918457\n",
      "Epoch 3, Loss: 25.358028411865234\n",
      "Epoch 4, Loss: 18.99384307861328\n",
      "Epoch 5, Loss: 7.055761337280273\n",
      "Epoch 6, Loss: 4.957239627838135\n",
      "Epoch 7, Loss: 11.948904037475586\n",
      "Epoch 8, Loss: 5.528303146362305\n",
      "Epoch 9, Loss: 7.121043682098389\n",
      "Epoch 10, Loss: 3.5987229347229004\n",
      "Epoch 11, Loss: 3.1117970943450928\n",
      "Epoch 12, Loss: 5.051759719848633\n",
      "Epoch 13, Loss: 5.323180198669434\n",
      "Epoch 14, Loss: 5.295496940612793\n",
      "Epoch 15, Loss: 5.512216091156006\n",
      "Epoch 16, Loss: 2.61767315864563\n",
      "Epoch 17, Loss: 2.3174641132354736\n",
      "Epoch 18, Loss: 2.889679193496704\n",
      "Epoch 19, Loss: 2.1674957275390625\n",
      "Epoch 20, Loss: 2.0500688552856445\n",
      "Epoch 21, Loss: 2.1264936923980713\n",
      "Epoch 22, Loss: 2.2720465660095215\n",
      "Epoch 23, Loss: 2.291386127471924\n",
      "Epoch 24, Loss: 2.290668249130249\n",
      "Epoch 25, Loss: 3.099295139312744\n",
      "Epoch 26, Loss: 1.9035975933074951\n",
      "Epoch 27, Loss: 2.6322290897369385\n",
      "Epoch 28, Loss: 2.431586980819702\n",
      "Epoch 29, Loss: 2.009538412094116\n",
      "Epoch 30, Loss: 1.9538650512695312\n",
      "Epoch 31, Loss: 1.9879204034805298\n",
      "Epoch 32, Loss: 1.8915101289749146\n",
      "Epoch 33, Loss: 1.880125641822815\n",
      "Epoch 34, Loss: 2.0020320415496826\n",
      "Epoch 35, Loss: 1.8769524097442627\n",
      "Epoch 36, Loss: 2.2112300395965576\n",
      "Epoch 37, Loss: 2.026211977005005\n",
      "Epoch 38, Loss: 1.9316169023513794\n",
      "Epoch 39, Loss: 1.9514873027801514\n",
      "Epoch 40, Loss: 2.050185203552246\n",
      "Epoch 41, Loss: 2.6515092849731445\n",
      "Epoch 42, Loss: 2.27193284034729\n",
      "Epoch 43, Loss: 1.9849807024002075\n",
      "Epoch 44, Loss: 1.9782092571258545\n",
      "Epoch 45, Loss: 1.8426433801651\n",
      "Epoch 46, Loss: 1.987620234489441\n",
      "Epoch 47, Loss: 1.8971432447433472\n",
      "Epoch 48, Loss: 1.9329084157943726\n",
      "Epoch 49, Loss: 1.9879919290542603\n",
      "Epoch 50, Loss: 1.9152826070785522\n",
      "Validation Accuracy: 0.1587\n",
      "Validation accuracy: 0.15873015873015872\n",
      "Training with lr=0.0001, hidden_sizes=[64, 128, 32], batch_size=32\n",
      "Epoch 1, Loss: 14.773533821105957\n",
      "Epoch 2, Loss: 13.961792945861816\n",
      "Epoch 3, Loss: 21.11481285095215\n",
      "Epoch 4, Loss: 16.078855514526367\n",
      "Epoch 5, Loss: 14.53178596496582\n",
      "Epoch 6, Loss: 9.342096328735352\n",
      "Epoch 7, Loss: 12.089913368225098\n",
      "Epoch 8, Loss: 10.690120697021484\n",
      "Epoch 9, Loss: 8.916629791259766\n",
      "Epoch 10, Loss: 12.32236385345459\n",
      "Epoch 11, Loss: 2.595008611679077\n",
      "Epoch 12, Loss: 4.47983455657959\n",
      "Epoch 13, Loss: 9.36259937286377\n",
      "Epoch 14, Loss: 2.513690710067749\n",
      "Epoch 15, Loss: 4.9849724769592285\n",
      "Epoch 16, Loss: 3.852832078933716\n",
      "Epoch 17, Loss: 4.5689697265625\n",
      "Epoch 18, Loss: 2.3638885021209717\n",
      "Epoch 19, Loss: 2.630396842956543\n",
      "Epoch 20, Loss: 3.3648903369903564\n",
      "Epoch 21, Loss: 3.993203639984131\n",
      "Epoch 22, Loss: 2.1196000576019287\n",
      "Epoch 23, Loss: 2.3306238651275635\n",
      "Epoch 24, Loss: 2.540677309036255\n",
      "Epoch 25, Loss: 2.19740891456604\n",
      "Epoch 26, Loss: 2.102419137954712\n",
      "Epoch 27, Loss: 2.085415840148926\n",
      "Epoch 28, Loss: 1.9003013372421265\n",
      "Epoch 29, Loss: 2.0327062606811523\n",
      "Epoch 30, Loss: 2.586442470550537\n",
      "Epoch 31, Loss: 1.861528754234314\n",
      "Epoch 32, Loss: 2.0518264770507812\n",
      "Epoch 33, Loss: 1.901387095451355\n",
      "Epoch 34, Loss: 2.449141025543213\n",
      "Epoch 35, Loss: 2.4921998977661133\n",
      "Epoch 36, Loss: 2.9768128395080566\n",
      "Epoch 37, Loss: 2.006474733352661\n",
      "Epoch 38, Loss: 1.926567554473877\n",
      "Epoch 39, Loss: 2.4152824878692627\n",
      "Epoch 40, Loss: 1.9767869710922241\n",
      "Epoch 41, Loss: 1.9100114107131958\n",
      "Epoch 42, Loss: 1.987611174583435\n",
      "Epoch 43, Loss: 2.1945643424987793\n",
      "Epoch 44, Loss: 2.047947406768799\n",
      "Epoch 45, Loss: 1.834170937538147\n",
      "Epoch 46, Loss: 1.9332900047302246\n",
      "Epoch 47, Loss: 1.911449909210205\n",
      "Epoch 48, Loss: 3.085900068283081\n",
      "Epoch 49, Loss: 2.068582534790039\n",
      "Epoch 50, Loss: 2.348006010055542\n",
      "Validation Accuracy: 0.1825\n",
      "Validation accuracy: 0.18253968253968253\n",
      "Training with lr=0.0001, hidden_sizes=[64, 128, 32], batch_size=64\n",
      "Epoch 1, Loss: 31.354917526245117\n",
      "Epoch 2, Loss: 28.850234985351562\n",
      "Epoch 3, Loss: 23.968576431274414\n",
      "Epoch 4, Loss: 23.021541595458984\n",
      "Epoch 5, Loss: 23.798255920410156\n",
      "Epoch 6, Loss: 18.47491455078125\n",
      "Epoch 7, Loss: 14.649689674377441\n",
      "Epoch 8, Loss: 11.354426383972168\n",
      "Epoch 9, Loss: 12.552358627319336\n",
      "Epoch 10, Loss: 11.247188568115234\n",
      "Epoch 11, Loss: 7.760715007781982\n",
      "Epoch 12, Loss: 8.275330543518066\n",
      "Epoch 13, Loss: 7.554154872894287\n",
      "Epoch 14, Loss: 15.171125411987305\n",
      "Epoch 15, Loss: 9.708097457885742\n",
      "Epoch 16, Loss: 9.31421184539795\n",
      "Epoch 17, Loss: 8.752385139465332\n",
      "Epoch 18, Loss: 6.4954938888549805\n",
      "Epoch 19, Loss: 3.7905097007751465\n",
      "Epoch 20, Loss: 4.828567028045654\n",
      "Epoch 21, Loss: 4.771174430847168\n",
      "Epoch 22, Loss: 4.9328742027282715\n",
      "Epoch 23, Loss: 4.815735340118408\n",
      "Epoch 24, Loss: 3.4863390922546387\n",
      "Epoch 25, Loss: 3.6156177520751953\n",
      "Epoch 26, Loss: 5.1187639236450195\n",
      "Epoch 27, Loss: 3.7546935081481934\n",
      "Epoch 28, Loss: 3.05078125\n",
      "Epoch 29, Loss: 3.519951581954956\n",
      "Epoch 30, Loss: 3.291358709335327\n",
      "Epoch 31, Loss: 3.2815983295440674\n",
      "Epoch 32, Loss: 4.035912036895752\n",
      "Epoch 33, Loss: 3.355726480484009\n",
      "Epoch 34, Loss: 3.294224500656128\n",
      "Epoch 35, Loss: 2.754124402999878\n",
      "Epoch 36, Loss: 2.844778299331665\n",
      "Epoch 37, Loss: 2.639160633087158\n",
      "Epoch 38, Loss: 2.830244779586792\n",
      "Epoch 39, Loss: 2.25101375579834\n",
      "Epoch 40, Loss: 2.288863182067871\n",
      "Epoch 41, Loss: 2.0516357421875\n",
      "Epoch 42, Loss: 2.3644940853118896\n",
      "Epoch 43, Loss: 3.2282660007476807\n",
      "Epoch 44, Loss: 2.8468539714813232\n",
      "Epoch 45, Loss: 2.512385129928589\n",
      "Epoch 46, Loss: 2.0302467346191406\n",
      "Epoch 47, Loss: 1.874191403388977\n",
      "Epoch 48, Loss: 2.4081344604492188\n",
      "Epoch 49, Loss: 3.461707830429077\n",
      "Epoch 50, Loss: 2.2512621879577637\n",
      "Validation Accuracy: 0.1587\n",
      "Validation accuracy: 0.15873015873015872\n",
      "Training with lr=0.0001, hidden_sizes=[64, 128, 32], batch_size=128\n",
      "Epoch 1, Loss: 29.536117553710938\n",
      "Epoch 2, Loss: 27.204484939575195\n",
      "Epoch 3, Loss: 25.25345802307129\n",
      "Epoch 4, Loss: 22.96352195739746\n",
      "Epoch 5, Loss: 21.18889045715332\n",
      "Epoch 6, Loss: 19.956039428710938\n",
      "Epoch 7, Loss: 18.608346939086914\n",
      "Epoch 8, Loss: 13.494476318359375\n",
      "Epoch 9, Loss: 18.02874755859375\n",
      "Epoch 10, Loss: 15.109175682067871\n",
      "Epoch 11, Loss: 12.159396171569824\n",
      "Epoch 12, Loss: 12.884846687316895\n",
      "Epoch 13, Loss: 13.52659797668457\n",
      "Epoch 14, Loss: 9.689186096191406\n",
      "Epoch 15, Loss: 12.225595474243164\n",
      "Epoch 16, Loss: 10.852715492248535\n",
      "Epoch 17, Loss: 8.418071746826172\n",
      "Epoch 18, Loss: 8.27560043334961\n",
      "Epoch 19, Loss: 8.691041946411133\n",
      "Epoch 20, Loss: 9.523600578308105\n",
      "Epoch 21, Loss: 7.162470817565918\n",
      "Epoch 22, Loss: 8.405301094055176\n",
      "Epoch 23, Loss: 7.488463401794434\n",
      "Epoch 24, Loss: 7.7123799324035645\n",
      "Epoch 25, Loss: 6.393896579742432\n",
      "Epoch 26, Loss: 6.9669694900512695\n",
      "Epoch 27, Loss: 5.279938697814941\n",
      "Epoch 28, Loss: 4.945498943328857\n",
      "Epoch 29, Loss: 5.024245738983154\n",
      "Epoch 30, Loss: 4.854471206665039\n",
      "Epoch 31, Loss: 4.253747940063477\n",
      "Epoch 32, Loss: 4.981271743774414\n",
      "Epoch 33, Loss: 5.1032328605651855\n",
      "Epoch 34, Loss: 3.635077476501465\n",
      "Epoch 35, Loss: 3.7170169353485107\n",
      "Epoch 36, Loss: 3.6338179111480713\n",
      "Epoch 37, Loss: 3.8923537731170654\n",
      "Epoch 38, Loss: 3.18100643157959\n",
      "Epoch 39, Loss: 4.180967807769775\n",
      "Epoch 40, Loss: 3.004167079925537\n",
      "Epoch 41, Loss: 3.868079900741577\n",
      "Epoch 42, Loss: 3.4831383228302\n",
      "Epoch 43, Loss: 2.8185365200042725\n",
      "Epoch 44, Loss: 3.72523832321167\n",
      "Epoch 45, Loss: 3.156975746154785\n",
      "Epoch 46, Loss: 2.930485725402832\n",
      "Epoch 47, Loss: 3.223670721054077\n",
      "Epoch 48, Loss: 3.1117990016937256\n",
      "Epoch 49, Loss: 2.6011528968811035\n",
      "Epoch 50, Loss: 3.191190242767334\n",
      "Validation Accuracy: 0.1720\n",
      "Validation accuracy: 0.17195767195767195\n",
      "Best parameters: {'input_size': 9, 'hidden_sizes': [128, 64, 32], 'lr': 0.001, 'epochs': 50, 'batch_size': 32}\n",
      "Best validation accuracy: 0.2962962962962963\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_accuracy = 0.0\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "for lr in hyperparameter_grid['lr']:\n",
    "    for hidden_sizes in hyperparameter_grid['hidden_sizes']:\n",
    "        for batch_size in hyperparameter_grid['batch_size']:\n",
    "            print(f\"Training with lr={lr}, hidden_sizes={hidden_sizes}, batch_size={batch_size}\")\n",
    "            params = {\n",
    "                'input_size': X_train_pca.shape[1],\n",
    "                'hidden_sizes': hidden_sizes,\n",
    "                'lr': lr,\n",
    "                'epochs': 50,  # Keeping epochs fixed for this example\n",
    "                'batch_size': batch_size,\n",
    "            }\n",
    "            \n",
    "            # Train and validate the model with the current set of parameters\n",
    "            val_accuracy, model = train_validate_model(train_dataset, val_dataset, device, params)\n",
    "            \n",
    "            print(f\"Validation accuracy: {val_accuracy}\")\n",
    "            if val_accuracy > best_accuracy:\n",
    "                best_accuracy = val_accuracy\n",
    "                best_params = params\n",
    "                best_model = model\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best validation accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9767d325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 28.50%\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(dataset=test_dataset, batch_size=best_params['batch_size'], shuffle=False)\n",
    "test_accuracy, test_predictions, test_actuals = test_model(best_model, test_loader, device)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b529db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
