{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea3e0c-e69d-4bc5-8fdb-cc346e9b8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some code for Image Processing [DEMO]\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import listdir\n",
    "#from os.path import isfile, join\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class Single_Image():\n",
    "\n",
    "    def __init__(self,img_path,img):\n",
    "        self.img_path = img_path\n",
    "        self.img_orig = img\n",
    "        self.img_cropped = None\n",
    "        self.img_crop_gray_norm = None\n",
    "        self.img_pca_approx = None\n",
    "        self.img_pca_features = None\n",
    "        self.img_lda_features = None\n",
    "        self.img_label = None\n",
    "\n",
    "    def add_cropped_img(self,img_cropped):\n",
    "        self.img_cropped = img_cropped\n",
    "\n",
    "    def add_gray_and_norm_img(self,img_gray_norm):\n",
    "        self.img_crop_gray_norm = img_gray_norm\n",
    "\n",
    "    def add_eigencomputations(self,new_features,img_pca_approx):\n",
    "        self.img_pca_features = new_features\n",
    "        self.img_pca_approx = img_pca_approx\n",
    "\n",
    "    def add_lda_features(self,new_features):\n",
    "        self.img_lda_features = new_features\n",
    "\n",
    "    def set_label(self,inp_label):\n",
    "        self.img_label = inp_label\n",
    "\n",
    "    def display_img(self, img_format):\n",
    "        #image = cv2.imread('img.jpg')\n",
    "        if img_format == 0:\n",
    "            image = cv2.cvtColor(self.img_orig,cv2.COLOR_BGR2RGB)\n",
    "            plt.imshow(image)\n",
    "            plt.title('Original Image')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        elif img_format == 1:\n",
    "            image = cv2.cvtColor(self.img_cropped,cv2.COLOR_BGR2RGB)\n",
    "            plt.imshow(image)\n",
    "            plt.title('Cropped Image')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        elif img_format == 2:\n",
    "            plt.imshow(self.img_crop_gray_norm,cmap='gray')\n",
    "            plt.title('Grayscale and Normalized Image')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        elif img_format == 3:\n",
    "            plt.imshow(self.img_pca_approx,cmap='gray')\n",
    "            plt.title('PCA Image')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            #image = cv2.cvtColor(self.img_cropped,cv2.COLOR_BGR2RGB)\n",
    "            pass\n",
    "\n",
    "class Image_Collection():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.img_obj_list = []\n",
    "        self.PCA_eigenvals = None\n",
    "        self.PCA_eigenvecs_dim_d = None\n",
    "        self.X = None\n",
    "        self.target = None\n",
    "\n",
    "    def add_image_to_list(self,img_path,img):\n",
    "        single_img_obj = Single_Image(img_path,img)\n",
    "        if \"type_55_nd\" in img_path or (\"type_55_pd\" in img_path):\n",
    "            single_img_obj.set_label(\"ND\")\n",
    "        elif (\"type_55_d\" in img_path):\n",
    "            #NOTE: here we err on the side of caution and classify possible defects as defects until otherwise\n",
    "            # determined by querying the SME (Subject Matter Expert) on the data.\n",
    "            single_img_obj.set_label(\"D\")\n",
    "        self.img_obj_list.append(single_img_obj)\n",
    "\n",
    "    def return_img_orig_list(self):\n",
    "        ret_list = []\n",
    "\n",
    "        for i in range(len(self.img_obj_list)):\n",
    "            img_orig = (self.img_obj_list[i]).img_orig\n",
    "            ret_list.append(img_orig)\n",
    "\n",
    "        return ret_list\n",
    "\n",
    "    def return_img_cropped_list(self):\n",
    "        ret_list = []\n",
    "\n",
    "        for i in range(len(self.img_obj_list)):\n",
    "            cropped_img = self.img_obj_list[i].cropped_img\n",
    "            ret_list.append(cropped_img)\n",
    "\n",
    "        return ret_list\n",
    "    def return_cropped_gray_img_list(self):\n",
    "        ret_list = []\n",
    "\n",
    "        for i in range(len(self.img_obj_list)):\n",
    "            gray_img = self.img_obj_list[i].img_cropped_gray\n",
    "            print(\"Gray Image Shape:\",gray_img.shape)\n",
    "            ret_list.append(gray_img)\n",
    "\n",
    "        ret_list = np.array(ret_list)\n",
    "        print(\"Gray List Array:\",ret_list.shape)\n",
    "\n",
    "        return ret_list\n",
    "\n",
    "    def crop_all_imgs(self,xmin,xmax,ymin,ymax):\n",
    "\n",
    "        for i in range(len(self.img_obj_list)):\n",
    "            cropped_img = self.img_obj_list[i].img_orig[xmin:xmax,ymin:ymax]\n",
    "            self.img_obj_list[i].add_cropped_img(cropped_img)\n",
    "\n",
    "    def grayscale_and_normalize(self):\n",
    "\n",
    "        for i in range(len(self.img_obj_list)):\n",
    "            img_gray = cv2.cvtColor(self.img_obj_list[i].img_cropped, cv2.COLOR_BGR2GRAY)\n",
    "            #print(np.max(img_gray.flatten()))\n",
    "            img_gray_norm = img_gray / 255 #Normalize by max gray value of 255\n",
    "            #print(np.max(img_gray_norm.flatten()))\n",
    "            self.img_obj_list[i].add_gray_and_norm_img(img_gray_norm)\n",
    "\n",
    "    def return_PCA_features(self):\n",
    "        ret_list = []\n",
    "\n",
    "        for i in range(len(self.img_obj_list)):\n",
    "            PCA_features = self.img_obj_list[i].img_pca_features\n",
    "            ret_list.append(PCA_features)\n",
    "\n",
    "        ret_list = np.array(ret_list)\n",
    "\n",
    "        return ret_list\n",
    "\n",
    "    def return_LDA_features(self):\n",
    "        ret_list = []\n",
    "\n",
    "        for i in range(len(self.img_obj_list)):\n",
    "            LDA_features = self.img_obj_list[i].img_lda_features\n",
    "            ret_list.append(LDA_features)\n",
    "\n",
    "        ret_list = np.array(ret_list)\n",
    "\n",
    "        return ret_list\n",
    "\n",
    "    def return_data_labels(self):\n",
    "        ret_list = []\n",
    "\n",
    "        for i in range(len(self.img_obj_list)):\n",
    "            img_label = self.img_obj_list[i].img_label\n",
    "            if img_label == \"ND\":\n",
    "                ret_list.append(0) #Encode Non-defective data as 0\n",
    "            elif img_label == \"D\":\n",
    "                ret_list.append(1) #Encode defective data as 1\n",
    "            else:\n",
    "                ret_list.append(None)\n",
    "\n",
    "        ret_list = np.array(ret_list)\n",
    "        return ret_list\n",
    "\n",
    "    def apply_PCA_on_all_images(self, n_components=110):\n",
    "        PCA_def = PCA(n_components)\n",
    "\n",
    "        vectorized_images = [] #Forms a n=110 * d=1.6302mil sized matrix\n",
    "        for i in range(len(self.img_obj_list)):\n",
    "            vectorized_img = np.reshape(self.img_obj_list[i].img_crop_gray_norm,-1)\n",
    "            vectorized_img_mean = np.mean(vectorized_img)\n",
    "            centered_img = vectorized_img - vectorized_img_mean #Subtract mean of image vector\n",
    "            vectorized_img_std_dev = np.std(vectorized_img)\n",
    "            vectorized_img = centered_img/vectorized_img_std_dev #Computed standard deviation of image vector\n",
    "            vectorized_images.append(vectorized_img)\n",
    "        vectorized_images = np.array(vectorized_images)\n",
    "\n",
    "        print(\"Vectorized Image Shape:\",vectorized_images[0].shape)\n",
    "\n",
    "        print(\"Pre-fit-transform\")\n",
    "        new_features = PCA_def.fit_transform(vectorized_images) #Coordinates in the lambda plane (plane of eigenvecs)\n",
    "        print(\"Post-fit-transform\")\n",
    "\n",
    "        exp_var_pca = PCA_def.explained_variance_ratio_\n",
    "        exp_var_cumul_sum = np.cumsum(exp_var_pca)\n",
    "        print(\"Explained Variance Ratio for PCA: \",exp_var_pca)\n",
    "        print(\"Explained variance Cumulative Sum for PCA: \",exp_var_cumul_sum)\n",
    "\n",
    "        ###### < REFACTOR THIS CODE\n",
    "        eigenvecs_dim_d = (PCA_def.components_).transpose() #Takes the row eigenvectors and turns it into column\n",
    "        eigenvals = PCA_def.explained_variance_\n",
    "        eigenvals_cumul_sum = np.cumsum(eigenvals)\n",
    "        print(\"Eigenvecs dim d shape:\",eigenvecs_dim_d.shape) #Should be 1630200x8 sized matrix (implementation detail)\n",
    "        #print(\"----------------------------------------------\")\n",
    "        #print(\"Explained Variance for PCA: \",eigenvals)\n",
    "        #print(\"Cumulative Explained Variance for PCA: \",eigenvals_cumul_sum)\n",
    "\n",
    "\n",
    "        # Create the visualization plot\n",
    "        # REFERENCE: https://vitalflux.com/pca-explained-variance-concept-python-example/\n",
    "        #plt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance ratio')\n",
    "        #plt.step(range(0,len(exp_var_cumul_sum)), exp_var_cumul_sum, where='mid',label='Cumulative explained variance ratio')\n",
    "        #plt.ylabel('Explained variance ratio', fontsize = 15)\n",
    "        #plt.xlabel('Principal component index', fontsize = 15)\n",
    "        #plt.legend(loc='best', fontsize = 15)\n",
    "        #plt.tight_layout()\n",
    "        #plt.show()\n",
    "\n",
    "        #plt.bar(range(0,len(eigenvals)), eigenvals, alpha=0.5, align='center', label='Individual explained variance')\n",
    "        #plt.step(range(0,len(eigenvals_cumul_sum)), eigenvals_cumul_sum, where='mid',label='Cumulative explained variance')\n",
    "        #plt.ylabel('Explained variance ratio', fontsize = 15)\n",
    "        #plt.xlabel('Principal component index', fontsize = 15)\n",
    "        #plt.legend(loc='best', fontsize = 15)\n",
    "        #plt.tight_layout()\n",
    "        #plt.show()\n",
    "        ###### >\n",
    "\n",
    "        #Add all the Eigenparams, as well as the Reconstructed Image using the new Eigenvectors\n",
    "        self.PCA_eigenvals = eigenvals\n",
    "        self.PCA_eigenvecs_dim_d = eigenvecs_dim_d\n",
    "\n",
    "        for i in range(len(self.img_obj_list)):\n",
    "            new_features_i = new_features[i].transpose()\n",
    "            img_pca_approx = np.matmul(eigenvecs_dim_d,new_features_i)\n",
    "            grayscale_dims = self.img_obj_list[i].img_crop_gray_norm.shape\n",
    "            img_pca_approx = np.reshape(img_pca_approx,(grayscale_dims[0],grayscale_dims[1]))\n",
    "            self.img_obj_list[i].add_eigencomputations(new_features[i],img_pca_approx)\n",
    "\n",
    "        print(\"PCA Transformation Complete\")\n",
    "\n",
    "    def apply_LDA_on_all_images(self, num_components=1):\n",
    "        LDA_def = LinearDiscriminantAnalysis(n_components=num_components)\n",
    "\n",
    "        vectorized_images = [] #Forms a n=110 * d=1.6302mil sized matrix\n",
    "        for i in range(len(self.img_obj_list)):\n",
    "            vectorized_img = np.reshape(self.img_obj_list[i].img_crop_gray_norm,-1)\n",
    "            vectorized_img_mean = np.mean(vectorized_img)\n",
    "            centered_img = vectorized_img - vectorized_img_mean #Subtract mean of image vector\n",
    "            vectorized_img_std_dev = np.std(vectorized_img)\n",
    "            vectorized_img = centered_img/vectorized_img_std_dev #Computed standard deviation of image vector\n",
    "            vectorized_images.append(vectorized_img)\n",
    "        vectorized_images = np.array(vectorized_images)\n",
    "\n",
    "        print(\"Vectorized Image Shape:\",vectorized_images[0].shape)\n",
    "\n",
    "        print(\"Pre-fit-transform\")\n",
    "        LDA_def.fit(vectorized_images,self.target)\n",
    "        new_features = LDA_def.transform(vectorized_images)\n",
    "        print(\"Post-fit-transform\")\n",
    "\n",
    "        exp_var_lda = LDA_def.explained_variance_ratio_\n",
    "        exp_var_cumul_sum = np.cumsum(exp_var_lda)\n",
    "        print(\"Explained Variance Ratio for LDA: \",exp_var_lda)\n",
    "        print(\"Explained variance Cumulative Sum for LDA: \",exp_var_cumul_sum)\n",
    "\n",
    "        ###### < REFACTOR THIS CODE\n",
    "        # Create the visualization plot\n",
    "        # REFERENCE: https://vitalflux.com/pca-explained-variance-concept-python-example/\n",
    "        # plt.bar(range(0,len(exp_var_lda)), exp_var_lda, alpha=0.5, align='center', label='Individual explained variance ratio')\n",
    "        # plt.step(range(0,len(exp_var_cumul_sum)), exp_var_cumul_sum, where='mid',label='Cumulative explained variance ratio')\n",
    "        # plt.ylabel('Explained variance ratio', fontsize = 15)\n",
    "        # plt.xlabel('Principal component index', fontsize = 15)\n",
    "        # plt.legend(loc='best', fontsize = 15)\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "        ###### >\n",
    "\n",
    "        for i in range(len(self.img_obj_list)):\n",
    "            self.img_obj_list[i].add_lda_features(new_features[i])\n",
    "\n",
    "        print(\"LDA Transformation Complete\")\n",
    "\n",
    "    def acquire_data(self,data):\n",
    "        self.X = data\n",
    "    def acquire_target(self,target):\n",
    "        self.target = target\n",
    "\n",
    "    def get_data_and_target(self):\n",
    "        return (self.X,self.target)\n",
    "\n",
    "class File_Reader():\n",
    "    '''\n",
    "    The FileReader class takes in a directory name and groups\n",
    "    all the image files into respective data class objects.\n",
    "    '''\n",
    "\n",
    "    def __init__(self,dirname,dataset_labels = []):\n",
    "        '''\n",
    "        :param dirname: directory name to extract images from\n",
    "        :param dataset_labels: should contain a category for each image type\n",
    "\n",
    "        This function initializes the class with the directory name and creates empty lists of associated subdirectories\n",
    "        and image filenames.\n",
    "        '''\n",
    "        self.dirname = dirname\n",
    "        self.subdirs = []\n",
    "        self.image_fnames = []\n",
    "        self.images = []\n",
    "\n",
    "    def enumerate_subdirs(self):\n",
    "        '''\n",
    "        This function gets subdirectories the parent directory and stores it into the self.subdirs variable (extends it)\n",
    "        '''\n",
    "        if self.subdirs != []:\n",
    "            self.subdirs = []\n",
    "\n",
    "        subdirs = listdir(\"./\" + self.dirname)\n",
    "        self.subdirs.extend(subdirs[:])\n",
    "\n",
    "    def enumerate_fnames_from_subdirs(self):\n",
    "        '''\n",
    "        This function iterates through all the subdirectories, gets the image filenames for each subdirectory and appends\n",
    "        it to the self.image_fnames list.\n",
    "        '''\n",
    "        for subdir in self.subdirs:\n",
    "            currpath = \"./\" + self.dirname + \"/\" + subdir + \"/\"\n",
    "            self.fnames = listdir(\"./\")\n",
    "            image_filenames = listdir(currpath)\n",
    "\n",
    "            for fname in image_filenames:\n",
    "                full_filepath = currpath + fname\n",
    "                self.image_fnames.append(full_filepath)\n",
    "\n",
    "                img_orig = cv2.imread(full_filepath)\n",
    "                self.images.append(img_orig)\n",
    "\n",
    "        #print(self.image_fnames[0:4])\n",
    "        #print(self.images[0:4])\n",
    "\n",
    "    def get_fnames_from_dir(self):\n",
    "        '''\n",
    "        gets subdirectories in a directory, and then gets all filenames from\n",
    "        '''\n",
    "\n",
    "        self.enumerate_subdirs()\n",
    "        self.enumerate_fnames_from_subdirs()\n",
    "\n",
    "        #print(self.image_fnames)\n",
    "        #print(len(self.image_fnames))\n",
    "\n",
    "        img_dataset = Image_Collection()\n",
    "\n",
    "        for i in range(len(self.image_fnames)):\n",
    "            #print(\"Image Names [i]:\",self.image_fnames[i])\n",
    "            img_dataset.add_image_to_list(self.image_fnames[i],self.images[i])\n",
    "        return img_dataset\n",
    "\n",
    "    def display_img(self,fname,fdescription=\"Input Image\"):\n",
    "        img = cv2.imread(fname)\n",
    "        cv2.imshow(fdescription,img)\n",
    "        cv2.waitKey(0)\n",
    "        print(img.shape)\n",
    "        new_img = cv2.resize(img,None,fx=0.5,fy=0.5)\n",
    "        cv2.imshow(fdescription,new_img)\n",
    "        cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
