{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fd5d6c-f38a-4f0d-be11-bf63fbefb889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUTHORS: Nithin Prasad, Murtadha Nisyif, Arpit Vaghela\n",
    "\n",
    "### Class and Library Imports [FUNCTIONAL]\n",
    "import sklearn #Scikit Learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc, RocCurveDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b950702-2346-4d52-96f2-d572f4e7c063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/hmnist_28_28_L.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### Data Exploration with the 28x28 image csv [FUNCTIONAL]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m project_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/hmnist_28_28_L.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m project_df\u001b[38;5;241m.\u001b[39mhead(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(project_df\u001b[38;5;241m.\u001b[39minfo())\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/hmnist_28_28_L.csv'"
     ]
    }
   ],
   "source": [
    "### Data Exploration with the 28x28 image csv [FUNCTIONAL]\n",
    "\n",
    "print(\"Hello\")\n",
    "project_df = pd.read_csv('data/hmnist_28_28_L.csv')\n",
    "project_df.head(n=4)\n",
    "print(project_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff3d32b6-e24a-4031-91ac-74e4bfb20a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- LABEL CHECK -----\n",
      "Number of labels of class 0 : 327\n",
      "Number of labels of class 1 : 514\n",
      "Number of labels of class 2 : 1099\n",
      "Number of labels of class 3 : 115\n",
      "Number of labels of class 4 : 6705\n",
      "Number of labels of class 5 : 142\n",
      "Number of labels of class 6 : 1113\n",
      "Total number of labels: 10015\n"
     ]
    }
   ],
   "source": [
    "### Check Dataset Balance [FUNCTIONAL]\n",
    "pixel_features = []\n",
    "for i in range(784):\n",
    "    str_i = str(i)\n",
    "    len_suffix = len(str_i)\n",
    "    pixel_feature = \"pixel\" + \"0\"*(4-len_suffix) + str_i\n",
    "    #print(pixel_name)\n",
    "    pixel_features.append(pixel_feature)\n",
    "\n",
    "#X = project_df.drop('label', axis = 1)\n",
    "Y = project_df['label']\n",
    "\n",
    "#Double check the number of Labels in set\n",
    "def check_set_balance(inp_set):\n",
    "    val_counts = inp_set.value_counts()\n",
    "    total_labels = 0\n",
    "    #print(type(val_counts))\n",
    "    for i in range(7):\n",
    "        num_i = val_counts[i]\n",
    "        print(\"Number of labels of class\",i,\":\",num_i)\n",
    "        total_labels += num_i\n",
    "        \n",
    "    print(\"Total number of labels:\",total_labels)\n",
    "\n",
    "print('----- LABEL CHECK -----')\n",
    "check_set_balance(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04efba8e-a6a4-49fc-a523-5572bcb2b049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n",
      "<class 'list'>\n",
      "[20, 24, 76, 131, 156, 169, 175, 185, 194, 190, 191, 190, 192, 186, 187, 188, 189, 184, 185, 180, 173, 136, 98, 59, 53, 56, 44, 30, 16, 49, 110, 156, 171, 168, 177, 189, 195, 197, 196, 194, 184, 189, 186, 187, 185, 181, 183, 193, 192, 166, 135, 83, 48, 55, 49, 34, 25, 87, 142, 175, 183, 173, 178, 191, 197, 205, 195, 175, 166, 168, 184, 178, 181, 184, 183, 195, 191, 183, 160, 112, 56, 47, 51, 39, 47, 116, 161, 184, 190, 185, 195, 190, 181, 197, 179, 167, 166, 163, 171, 170, 169, 170, 181, 192, 188, 187, 165, 136, 80, 44, 49, 42, 83, 138, 174, 188, 196, 190, 194, 178, 169, 171, 171, 175, 167, 165, 163, 164, 155, 161, 176, 186, 190, 178, 171, 154, 110, 51, 44, 44, 113, 157, 179, 191, 192, 197, 187, 168, 176, 176, 176, 179, 172, 161, 163, 163, 159, 162, 176, 179, 185, 178, 177, 175, 136, 69, 38, 43, 134, 165, 180, 187, 197, 191, 188, 170, 175, 176, 174, 180, 183, 167, 166, 175, 167, 164, 179, 185, 182, 189, 196, 189, 153, 86, 37, 39, 148, 171, 178, 190, 202, 197, 194, 170, 169, 180, 175, 177, 185, 182, 171, 178, 176, 162, 175, 180, 186, 198, 201, 199, 169, 106, 43, 35, 155, 170, 180, 197, 202, 200, 181, 164, 169, 181, 183, 180, 179, 185, 176, 171, 171, 154, 173, 181, 198, 200, 195, 201, 178, 128, 51, 30, 163, 174, 181, 195, 203, 194, 176, 162, 166, 179, 187, 185, 183, 174, 176, 171, 152, 158, 186, 191, 195, 197, 193, 193, 187, 138, 60, 28, 173, 181, 181, 191, 203, 185, 169, 159, 160, 175, 191, 194, 186, 171, 164, 174, 168, 188, 194, 195, 191, 197, 192, 196, 181, 139, 66, 25, 173, 186, 185, 192, 201, 194, 168, 167, 167, 178, 189, 180, 193, 195, 177, 177, 191, 198, 194, 195, 187, 185, 190, 192, 179, 146, 75, 23, 170, 182, 194, 197, 193, 201, 190, 167, 171, 162, 173, 172, 198, 205, 198, 186, 183, 201, 202, 191, 186, 182, 192, 190, 188, 160, 82, 22, 170, 180, 191, 194, 168, 180, 192, 174, 179, 157, 180, 190, 188, 198, 182, 175, 190, 196, 192, 188, 188, 183, 195, 192, 186, 160, 86, 20, 174, 180, 184, 200, 200, 188, 175, 180, 184, 176, 189, 193, 191, 184, 177, 181, 189, 188, 184, 181, 179, 180, 187, 188, 185, 155, 82, 18, 167, 187, 192, 193, 204, 197, 173, 172, 182, 183, 183, 190, 190, 184, 179, 186, 178, 185, 185, 177, 183, 191, 182, 175, 189, 149, 72, 15, 169, 187, 193, 196, 200, 191, 185, 173, 175, 181, 177, 166, 193, 188, 191, 188, 173, 170, 177, 176, 194, 197, 189, 190, 189, 150, 62, 13, 167, 184, 192, 203, 202, 199, 191, 172, 172, 186, 179, 152, 177, 176, 191, 188, 170, 174, 164, 175, 205, 204, 194, 192, 182, 145, 51, 11, 157, 185, 191, 200, 208, 207, 186, 171, 164, 181, 174, 162, 169, 178, 183, 183, 182, 170, 165, 174, 197, 206, 195, 192, 172, 130, 38, 11, 141, 179, 186, 184, 199, 204, 202, 167, 156, 171, 164, 167, 157, 157, 177, 180, 171, 163, 168, 175, 200, 202, 195, 197, 170, 112, 29, 11, 125, 172, 184, 181, 184, 198, 203, 169, 164, 173, 160, 157, 153, 157, 176, 179, 165, 158, 168, 180, 200, 198, 192, 193, 161, 95, 22, 10, 103, 157, 181, 184, 192, 195, 197, 198, 207, 184, 154, 149, 151, 151, 178, 176, 158, 156, 167, 181, 198, 187, 179, 174, 134, 63, 12, 12, 81, 131, 171, 183, 187, 193, 196, 198, 203, 194, 154, 140, 133, 161, 172, 165, 155, 152, 159, 179, 189, 178, 179, 155, 98, 26, 12, 10, 63, 114, 155, 177, 181, 189, 198, 196, 201, 198, 169, 143, 140, 161, 162, 162, 154, 155, 165, 183, 182, 178, 168, 133, 63, 14, 15, 7, 52, 85, 132, 166, 185, 182, 192, 195, 198, 196, 189, 158, 150, 160, 164, 162, 146, 153, 180, 183, 173, 171, 152, 101, 30, 16, 14, 5, 53, 60, 107, 153, 175, 175, 185, 186, 193, 190, 199, 186, 164, 174, 170, 156, 137, 151, 174, 173, 170, 155, 122, 56, 17, 19, 10, 3, 56, 55, 73, 117, 153, 176, 178, 188, 189, 180, 187, 197, 186, 185, 182, 168, 165, 164, 171, 172, 161, 126, 71, 24, 21, 17, 7, 2, 51, 59, 56, 81, 124, 155, 169, 180, 185, 178, 166, 188, 182, 183, 186, 180, 180, 165, 155, 159, 129, 82, 35, 23, 22, 13, 4, 3, 0]\n",
      "[20, 24, 76, 131, 156, 169, 175, 185, 194, 190, 191, 190, 192, 186, 187, 188, 189, 184, 185, 180, 173, 136, 98, 59, 53, 56, 44, 30, 16, 49, 110, 156, 171, 168, 177, 189, 195, 197, 196, 194, 184, 189, 186, 187, 185, 181, 183, 193, 192, 166, 135, 83, 48, 55, 49, 34, 25, 87, 142, 175, 183, 173, 178, 191, 197, 205, 195, 175, 166, 168, 184, 178, 181, 184, 183, 195, 191, 183, 160, 112, 56, 47, 51, 39, 47, 116, 161, 184, 190, 185, 195, 190, 181, 197, 179, 167, 166, 163, 171, 170, 169, 170, 181, 192, 188, 187, 165, 136, 80, 44, 49, 42, 83, 138, 174, 188, 196, 190, 194, 178, 169, 171, 171, 175, 167, 165, 163, 164, 155, 161, 176, 186, 190, 178, 171, 154, 110, 51, 44, 44, 113, 157, 179, 191, 192, 197, 187, 168, 176, 176, 176, 179, 172, 161, 163, 163, 159, 162, 176, 179, 185, 178, 177, 175, 136, 69, 38, 43, 134, 165, 180, 187, 197, 191, 188, 170, 175, 176, 174, 180, 183, 167, 166, 175, 167, 164, 179, 185, 182, 189, 196, 189, 153, 86, 37, 39, 148, 171, 178, 190, 202, 197, 194, 170, 169, 180, 175, 177, 185, 182, 171, 178, 176, 162, 175, 180, 186, 198, 201, 199, 169, 106, 43, 35, 155, 170, 180, 197, 202, 200, 181, 164, 169, 181, 183, 180, 179, 185, 176, 171, 171, 154, 173, 181, 198, 200, 195, 201, 178, 128, 51, 30, 163, 174, 181, 195, 203, 194, 176, 162, 166, 179, 187, 185, 183, 174, 176, 171, 152, 158, 186, 191, 195, 197, 193, 193, 187, 138, 60, 28, 173, 181, 181, 191, 203, 185, 169, 159, 160, 175, 191, 194, 186, 171, 164, 174, 168, 188, 194, 195, 191, 197, 192, 196, 181, 139, 66, 25, 173, 186, 185, 192, 201, 194, 168, 167, 167, 178, 189, 180, 193, 195, 177, 177, 191, 198, 194, 195, 187, 185, 190, 192, 179, 146, 75, 23, 170, 182, 194, 197, 193, 201, 190, 167, 171, 162, 173, 172, 198, 205, 198, 186, 183, 201, 202, 191, 186, 182, 192, 190, 188, 160, 82, 22, 170, 180, 191, 194, 168, 180, 192, 174, 179, 157, 180, 190, 188, 198, 182, 175, 190, 196, 192, 188, 188, 183, 195, 192, 186, 160, 86, 20, 174, 180, 184, 200, 200, 188, 175, 180, 184, 176, 189, 193, 191, 184, 177, 181, 189, 188, 184, 181, 179, 180, 187, 188, 185, 155, 82, 18, 167, 187, 192, 193, 204, 197, 173, 172, 182, 183, 183, 190, 190, 184, 179, 186, 178, 185, 185, 177, 183, 191, 182, 175, 189, 149, 72, 15, 169, 187, 193, 196, 200, 191, 185, 173, 175, 181, 177, 166, 193, 188, 191, 188, 173, 170, 177, 176, 194, 197, 189, 190, 189, 150, 62, 13, 167, 184, 192, 203, 202, 199, 191, 172, 172, 186, 179, 152, 177, 176, 191, 188, 170, 174, 164, 175, 205, 204, 194, 192, 182, 145, 51, 11, 157, 185, 191, 200, 208, 207, 186, 171, 164, 181, 174, 162, 169, 178, 183, 183, 182, 170, 165, 174, 197, 206, 195, 192, 172, 130, 38, 11, 141, 179, 186, 184, 199, 204, 202, 167, 156, 171, 164, 167, 157, 157, 177, 180, 171, 163, 168, 175, 200, 202, 195, 197, 170, 112, 29, 11, 125, 172, 184, 181, 184, 198, 203, 169, 164, 173, 160, 157, 153, 157, 176, 179, 165, 158, 168, 180, 200, 198, 192, 193, 161, 95, 22, 10, 103, 157, 181, 184, 192, 195, 197, 198, 207, 184, 154, 149, 151, 151, 178, 176, 158, 156, 167, 181, 198, 187, 179, 174, 134, 63, 12, 12, 81, 131, 171, 183, 187, 193, 196, 198, 203, 194, 154, 140, 133, 161, 172, 165, 155, 152, 159, 179, 189, 178, 179, 155, 98, 26, 12, 10, 63, 114, 155, 177, 181, 189, 198, 196, 201, 198, 169, 143, 140, 161, 162, 162, 154, 155, 165, 183, 182, 178, 168, 133, 63, 14, 15, 7, 52, 85, 132, 166, 185, 182, 192, 195, 198, 196, 189, 158, 150, 160, 164, 162, 146, 153, 180, 183, 173, 171, 152, 101, 30, 16, 14, 5, 53, 60, 107, 153, 175, 175, 185, 186, 193, 190, 199, 186, 164, 174, 170, 156, 137, 151, 174, 173, 170, 155, 122, 56, 17, 19, 10, 3, 56, 55, 73, 117, 153, 176, 178, 188, 189, 180, 187, 197, 186, 185, 182, 168, 165, 164, 171, 172, 161, 126, 71, 24, 21, 17, 7, 2, 51, 59, 56, 81, 124, 155, 169, 180, 185, 178, 166, 188, 182, 183, 186, 180, 180, 165, 155, 159, 129, 82, 35, 23, 22, 13, 4, 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Get and Display a sample row of the data [DEMO]\n",
    "project_df.loc[project_df['label'] == 0]\n",
    "sample_image_vec = list(project_df.iloc[9687])\n",
    "print(len(sample_image_vec))\n",
    "print(type(sample_image_vec))\n",
    "print(sample_image_vec)\n",
    "sample_image_vec.pop(-1)\n",
    "print(sample_image_vec)\n",
    "sample_image_vec = np.array(sample_image_vec)\n",
    "sample_image = np.reshape(sample_image_vec,(28,28))\n",
    "#print(sample_image)\n",
    "plt.imshow(sample_image,cmap='gray')\n",
    "plt.title('Grayscale Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d16c6ae-9822-40a2-9745-506217f78787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1892\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1892 entries, 0 to 10014\n",
      "Columns: 785 entries, pixel0000 to label\n",
      "dtypes: int64(785)\n",
      "memory usage: 11.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### Employ a pseudo-balancing of the data.\n",
    "### Uses all of Class 3 (115 images), Class 5 (142 images) and only 327 random images from classes [0,1,2,4,6].\n",
    "\n",
    "row_indices = []\n",
    "\n",
    "for label_i in range(7):\n",
    "    # Find all the rows of the dataframe corresponding to label i\n",
    "    rows_of_i = project_df.loc[project_df['label'] == label_i]\n",
    "    indices_of_i = list(rows_of_i.index)\n",
    "    indices_of_i_random = random.sample(indices_of_i,min(327,len(rows_of_i)))\n",
    "\n",
    "    row_indices.extend(indices_of_i_random)\n",
    "\n",
    "row_indices.sort()\n",
    "\n",
    "print(len(row_indices)) #Should print 1892.\n",
    "\n",
    "working_df = project_df.iloc[row_indices]\n",
    "print(working_df.info())\n",
    "# print(working_df.head(n=5))\n",
    "\n",
    "### save the working df as a csv file\n",
    "# working_df.to_csv(\"./data/skin_cancer_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf10dcc-dda9-4a15-9e06-d87c9dc584ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1135, 378, 379)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Do Train-Validation-Test Split on the Data (eg. 60/20/20)\n",
    "\n",
    "#read csv\n",
    "df = pd.read_csv('./data/skin_cancer_dataset.csv')\n",
    "\n",
    "#separate the features and labels\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "#split 60-40 for training dataset and a temp dataset that will be split to 50-50\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Second split of the temporary set: 50% for validation and 50% for test set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "#sanity check\n",
    "sizes = (len(X_train), len(X_val), len(X_test))\n",
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffed339d-a3f0-43b9-bbf8-f9a8d94b2299",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply PCA (fit the PCA matrix using ONLY the training portion of the dataset). Transform each separately\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# fit pca on the training set only\n",
    "pca = PCA(n_components=0.90, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "#sanity check\n",
    "X_train_pca.shape\n",
    "\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "X_val_pca = pca.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67f8817c-0e63-429e-bacf-0f035c85b6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Implement MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_clf = MLPClassifier()\n",
    "\n",
    "mlp_clf.fit(X_train_pca, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d419c7ba-df26-4028-a94b-ab46b69853ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Execute MLP Model and Print Metrics\n",
    "y_test_pred = mlp_clf.predict(X_test_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb97817a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2849604221635884\n",
      "F1 Score: 0.2854603459397499\n",
      "Confusion Matrix:\n",
      "[[17 16 11  3  3  3  6]\n",
      " [10 20 16  2  2  7  8]\n",
      " [15  3 24  3  6  4 12]\n",
      " [ 6  8  5  4  1  1  4]\n",
      " [ 8  8 12  4 20  7 13]\n",
      " [ 3  4  4  0  5  5  4]\n",
      " [ 7  7 15  1  9  5 18]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.29      0.27        59\n",
      "           1       0.30      0.31      0.31        65\n",
      "           2       0.28      0.36      0.31        67\n",
      "           3       0.24      0.14      0.17        29\n",
      "           4       0.43      0.28      0.34        72\n",
      "           5       0.16      0.20      0.18        25\n",
      "           6       0.28      0.29      0.28        62\n",
      "\n",
      "    accuracy                           0.28       379\n",
      "   macro avg       0.28      0.27      0.27       379\n",
      "weighted avg       0.30      0.28      0.29       379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# # Generate ROC curve\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# # Plot ROC curve\n",
    "# roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='MLP Classifier')\n",
    "# roc_display.plot()\n",
    "# plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.show()\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(y_test, y_test_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6b9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 588 candidates, totalling 2940 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameter tuning\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'activation': ['logistic', 'tanh', 'relu', 'leaky_relu', 'elu', 'softplus', 'swish'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'max_iter': [200, 500, 1000, 1500, 2000, 2500, 3000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(mlp_clf, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "\n",
    "grid_search.fit(X_val_pca, y_val)\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd5af559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with best parameters: 0.3087071240105541\n"
     ]
    }
   ],
   "source": [
    "# Best parameters found:\n",
    "# {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'max_iter': 200}\n",
    "\n",
    "# Create MLPClassifier with increased max_iter\n",
    "best_mlp_clf = MLPClassifier(activation='logistic', alpha=0.0001, hidden_layer_sizes=(50, 50), max_iter=1500)\n",
    "\n",
    "# Train the model\n",
    "best_mlp_clf.fit(X_train_pca, y_train)\n",
    "\n",
    "# Evaluate performance on test set\n",
    "test_accuracy = best_mlp_clf.score(X_test_pca, y_test)\n",
    "print(\"Test Accuracy with best parameters:\", test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac55c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
